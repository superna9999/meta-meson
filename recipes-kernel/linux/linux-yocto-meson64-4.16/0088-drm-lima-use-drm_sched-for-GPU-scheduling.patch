From 9206290bec3b6aec2422c807bde82055041979b7 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Wed, 7 Feb 2018 17:42:20 +0800
Subject: [PATCH] drm/lima: use drm_sched for GPU scheduling

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 drivers/gpu/drm/lima/Kconfig      |   1 +
 drivers/gpu/drm/lima/lima.h       |  11 +-
 drivers/gpu/drm/lima/lima_drv.c   |  27 ++-
 drivers/gpu/drm/lima/lima_gem.c   |  28 ++-
 drivers/gpu/drm/lima/lima_gp.c    |  18 +-
 drivers/gpu/drm/lima/lima_pp.c    |  12 +-
 drivers/gpu/drm/lima/lima_sched.c | 415 +++++++++++++++++++-------------------
 drivers/gpu/drm/lima/lima_sched.h |  48 +++--
 8 files changed, 299 insertions(+), 261 deletions(-)

diff --git a/drivers/gpu/drm/lima/Kconfig b/drivers/gpu/drm/lima/Kconfig
index b4ef4fd..435d6d3 100644
--- a/drivers/gpu/drm/lima/Kconfig
+++ b/drivers/gpu/drm/lima/Kconfig
@@ -3,5 +3,6 @@ config DRM_LIMA
        tristate "LIMA (DRM support for ARM Mali 400/450 GPU)"
        depends on DRM
        depends on ARCH_SUNXI || ARCH_ROCKCHIP || ARCH_EXYNOS || ARCH_MESON
+       select DRM_SCHED
        help
          DRM driver for ARM Mali 400/450 GPUs.
diff --git a/drivers/gpu/drm/lima/lima.h b/drivers/gpu/drm/lima/lima.h
index 9ed01e7..3094c2c 100644
--- a/drivers/gpu/drm/lima/lima.h
+++ b/drivers/gpu/drm/lima/lima.h
@@ -91,6 +91,8 @@ struct lima_pp {
 	atomic_t task;
 };
 
+#define LIMA_MAX_PIPE 2
+
 struct lima_device {
 	struct device *dev;
 	struct drm_device *ddev;
@@ -108,7 +110,7 @@ struct lima_device {
 
 	struct lima_l2_cache *l2_cache;
 
-	struct lima_sched_pipe *pipe[2];
+	struct lima_sched_pipe *pipe[LIMA_MAX_PIPE];
 
 	struct lima_gp *gp;
 	struct lima_pp *pp;
@@ -119,6 +121,7 @@ struct lima_device {
 
 struct lima_drm_priv {
 	struct lima_vm *vm;
+	struct lima_sched_context context[LIMA_MAX_PIPE];
 };
 
 struct lima_bo_va_mapping {
@@ -161,9 +164,9 @@ int lima_gem_mmap_offset(struct drm_file *file, u32 handle, u64 *offset);
 int lima_gem_mmap(struct file *filp, struct vm_area_struct *vma);
 int lima_gem_va_map(struct drm_file *file, u32 handle, u32 flags, u32 va);
 int lima_gem_va_unmap(struct drm_file *file, u32 handle, u32 va);
-int lima_gem_submit(struct drm_file *file, struct lima_sched_pipe *pipe,
-		    struct drm_lima_gem_submit_bo *bos, u32 nr_bos,
-		    void *frame, u32 *fence);
+int lima_gem_submit(struct drm_file *file, int pipe,
+		    struct drm_lima_gem_submit_bo *bos,
+		    u32 nr_bos, void *frame, u32 *fence);
 int lima_gem_wait(struct drm_file *file, u32 handle, u32 op, u64 timeout_ns);
 struct drm_gem_object *lima_gem_prime_import_sg_table(struct drm_device *dev,
 						      struct dma_buf_attachment *attach,
diff --git a/drivers/gpu/drm/lima/lima_drv.c b/drivers/gpu/drm/lima/lima_drv.c
index fecb631..ac9783d 100644
--- a/drivers/gpu/drm/lima/lima_drv.c
+++ b/drivers/gpu/drm/lima/lima_drv.c
@@ -118,8 +118,7 @@ static int lima_ioctl_gem_submit(struct drm_device *dev, void *data, struct drm_
 		break;
 	}
 
-	err = lima_gem_submit(file, ldev->pipe[args->pipe], bos, args->nr_bos,
-			      frame, &args->fence);
+	err = lima_gem_submit(file, args->pipe, bos, args->nr_bos, frame, &args->fence);
 
 out1:
 	if (err)
@@ -132,12 +131,13 @@ static int lima_ioctl_gem_submit(struct drm_device *dev, void *data, struct drm_
 static int lima_ioctl_wait_fence(struct drm_device *dev, void *data, struct drm_file *file)
 {
 	struct drm_lima_wait_fence *args = data;
-	struct lima_device *ldev = to_lima_dev(dev);
+	struct lima_drm_priv *priv = file->driver_priv;
 
-	if (args->pipe >= ARRAY_SIZE(ldev->pipe))
+	if (args->pipe >= ARRAY_SIZE(priv->context))
 		return -EINVAL;
 
-	return lima_sched_pipe_wait_fence(ldev->pipe[args->pipe], args->fence, args->timeout_ns);
+	return lima_sched_context_wait_fence(priv->context + args->pipe,
+					     args->fence, args->timeout_ns);
 }
 
 static int lima_ioctl_gem_wait(struct drm_device *dev, void *data, struct drm_file *file)
@@ -152,7 +152,7 @@ static int lima_ioctl_gem_wait(struct drm_device *dev, void *data, struct drm_fi
 
 static int lima_drm_driver_open(struct drm_device *dev, struct drm_file *file)
 {
-	int err;
+	int err, i;
 	struct lima_drm_priv *priv;
 	struct lima_device *ldev = to_lima_dev(dev);
 
@@ -166,9 +166,19 @@ static int lima_drm_driver_open(struct drm_device *dev, struct drm_file *file)
 		goto err_out0;
 	}
 
+	for (i = 0; i < LIMA_MAX_PIPE; i++) {
+		err = lima_sched_context_init(ldev->pipe[i], priv->context + i);
+		if (err)
+			goto err_out1;
+	}
+
 	file->driver_priv = priv;
 	return 0;
 
+err_out1:
+	for (i--; i >= 0; i--)
+		lima_sched_context_fini(ldev->pipe[i], priv->context + i);
+	lima_vm_put(priv->vm);
 err_out0:
 	kfree(priv);
 	return err;
@@ -177,6 +187,11 @@ static int lima_drm_driver_open(struct drm_device *dev, struct drm_file *file)
 static void lima_drm_driver_postclose(struct drm_device *dev, struct drm_file *file)
 {
 	struct lima_drm_priv *priv = file->driver_priv;
+	struct lima_device *ldev = to_lima_dev(dev);
+	int i;
+
+	for (i = 0; i < LIMA_MAX_PIPE; i++)
+		lima_sched_context_fini(ldev->pipe[i], priv->context + i);
 
 	lima_vm_put(priv->vm);
 	kfree(priv);
diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index 6321cf8..ccb9b3c 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -374,11 +374,11 @@ static int lima_gem_lock_bos(struct lima_bo **bos, u32 nr_bos,
 	return ret;
 }
 
-static int lima_gem_sync_bo(struct lima_sched_task *task, u64 context,
-			    struct lima_bo *bo, bool write)
+static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo, bool write)
 {
 	int i, err;
 	struct dma_fence *f;
+	u64 context = task->base.s_fence->finished.context;
 
 	if (write) {
 		struct reservation_object_list *fobj =
@@ -413,9 +413,9 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, u64 context,
 	return 0;
 }
 
-int lima_gem_submit(struct drm_file *file, struct lima_sched_pipe *pipe,
-		    struct drm_lima_gem_submit_bo *bos, u32 nr_bos,
-		    void *frame, u32 *fence)
+int lima_gem_submit(struct drm_file *file, int pipe,
+		    struct drm_lima_gem_submit_bo *bos,
+		    u32 nr_bos, void *frame, u32 *fence)
 {
 	struct lima_bo **lbos;
 	int i, err = 0;
@@ -442,32 +442,28 @@ int lima_gem_submit(struct drm_file *file, struct lima_sched_pipe *pipe,
 	if (err)
 		goto out0;
 
-	task = lima_sched_task_create(priv->vm, frame);
+	task = lima_sched_task_create(priv->context + pipe, priv->vm, frame);
 	if (IS_ERR(task)) {
 		err = PTR_ERR(task);
 		goto out1;
 	}
 
 	for (i = 0; i < nr_bos; i++) {
-		err = lima_gem_sync_bo(task, pipe->fence_context, lbos[i],
-				       bos[i].flags & LIMA_SUBMIT_BO_WRITE);
+		err = lima_gem_sync_bo(task, lbos[i], bos[i].flags & LIMA_SUBMIT_BO_WRITE);
 		if (err)
 			goto out2;
 	}
 
-	err = lima_sched_task_queue(pipe, task);
-	if (err)
-		goto out2;
-
 	for (i = 0; i < nr_bos; i++) {
 		if (bos[i].flags & LIMA_SUBMIT_BO_WRITE)
-			reservation_object_add_excl_fence(lbos[i]->resv, task->fence);
+			reservation_object_add_excl_fence(
+				lbos[i]->resv, &task->base.s_fence->finished);
 		else
-			reservation_object_add_shared_fence(lbos[i]->resv, task->fence);
+			reservation_object_add_shared_fence(
+				lbos[i]->resv, &task->base.s_fence->finished);
 	}
-	dma_fence_put(task->fence);
 
-	*fence = task->fence->seqno;
+	*fence = lima_sched_context_queue_task(priv->context + pipe, task);
 
 out2:
 	if (err)
diff --git a/drivers/gpu/drm/lima/lima_gp.c b/drivers/gpu/drm/lima/lima_gp.c
index ad29541..9cd2996 100644
--- a/drivers/gpu/drm/lima/lima_gp.c
+++ b/drivers/gpu/drm/lima/lima_gp.c
@@ -106,6 +106,7 @@ static irqreturn_t lima_gp_irq_handler(int irq, void *data)
 	struct lima_gp *gp = data;
 	struct lima_device *dev = gp->ip.dev;
 	u32 state = gp_read(INT_STAT);
+	bool task_done = false, fail = false;
 
 	/* for shared irq case */
 	if (!state)
@@ -113,13 +114,14 @@ static irqreturn_t lima_gp_irq_handler(int irq, void *data)
 
 	if (state & LIMA_GP_IRQ_MASK_ERROR) {
 		u32 status = gp_read(STATUS);
+
 		dev_info(dev->dev, "gp error irq state=%x status=%x\n",
 			 state, status);
-		lima_sched_pipe_task_done(&gp->pipe, true);
+
+		fail = true;
+		task_done = true;
 	}
 	else {
-		bool task_done = false;
-
 		if (state & LIMA_GP_IRQ_VS_END_CMD_LST) {
 			gp->task &= ~LIMA_GP_TASK_VS;
 			task_done = true;
@@ -129,12 +131,16 @@ static irqreturn_t lima_gp_irq_handler(int irq, void *data)
 			gp->task &= ~LIMA_GP_TASK_PLBU;
 			task_done = true;
 		}
-
-		if (task_done && !gp->task)
-			lima_sched_pipe_task_done(&gp->pipe, false);
 	}
 
 	gp_write(INT_CLEAR, state);
+
+	if (task_done) {
+		if (fail)
+			lima_sched_pipe_task_done(&gp->pipe, true);
+		else if (!gp->task)
+			lima_sched_pipe_task_done(&gp->pipe, false);
+	}
 	return IRQ_HANDLED;
 }
 
diff --git a/drivers/gpu/drm/lima/lima_pp.c b/drivers/gpu/drm/lima/lima_pp.c
index 9357c94..ba2e31d 100644
--- a/drivers/gpu/drm/lima/lima_pp.c
+++ b/drivers/gpu/drm/lima/lima_pp.c
@@ -89,6 +89,7 @@ static irqreturn_t lima_pp_core_irq_handler(int irq, void *data)
 	struct lima_device *dev = core->ip.dev;
 	struct lima_pp *pp = dev->pp;
 	u32 state = pp_read(INT_STATUS);
+	bool task_done = false, fail = false;
 
 	/* for shared irq case */
 	if (!state)
@@ -96,17 +97,24 @@ static irqreturn_t lima_pp_core_irq_handler(int irq, void *data)
 
 	if (state & LIMA_PP_IRQ_MASK_ERROR) {
 		u32 status = pp_read(STATUS);
+
 		dev_info(dev->dev, "pp error irq state=%x status=%x\n",
 			 state, status);
-		lima_sched_pipe_task_done(&pp->pipe, true);
+
+		task_done = true;
+		fail = true;
 	}
 	else {
 		if ((state & LIMA_PP_IRQ_END_OF_FRAME) &&
 		    atomic_dec_and_test(&pp->task))
-			lima_sched_pipe_task_done(&pp->pipe, false);
+			task_done = true;
 	}
 
 	pp_write(INT_CLEAR, state);
+
+	if (task_done)
+		lima_sched_pipe_task_done(&pp->pipe, fail);
+
 	return IRQ_HANDLED;
 }
 
diff --git a/drivers/gpu/drm/lima/lima_sched.c b/drivers/gpu/drm/lima/lima_sched.c
index 7995f51..7c379c3 100644
--- a/drivers/gpu/drm/lima/lima_sched.c
+++ b/drivers/gpu/drm/lima/lima_sched.c
@@ -21,7 +21,7 @@ static const char *lima_fence_get_timeline_name(struct dma_fence *fence)
 {
 	struct lima_fence *f = to_lima_fence(fence);
 
-	return f->pipe->name;
+	return f->pipe->base.name;
 }
 
 static bool lima_fence_enable_signaling(struct dma_fence *fence)
@@ -44,16 +44,43 @@ static const struct dma_fence_ops lima_fence_ops = {
 	.release = lima_fence_release,
 };
 
-struct lima_sched_task *lima_sched_task_create(struct lima_vm *vm, void *frame)
+static inline struct lima_sched_task *to_lima_task(struct drm_sched_job *job)
+{
+	return container_of(job, struct lima_sched_task, base);
+}
+
+static inline struct lima_sched_pipe *to_lima_pipe(struct drm_gpu_scheduler *sched)
+{
+	return container_of(sched, struct lima_sched_pipe, base);
+}
+
+struct lima_sched_task *lima_sched_task_create(struct lima_sched_context *context,
+					       struct lima_vm *vm, void *frame)
 {
 	struct lima_sched_task *task;
+	struct lima_fence *fence;
+	int err;
 
 	task = kzalloc(sizeof(*task), GFP_KERNEL);
 	if (!task)
 		return ERR_PTR(-ENOMEM);
 
+	err = drm_sched_job_init(&task->base, context->base.sched,
+				 &context->base, context);
+	if (err) {
+		kfree(task);
+		return ERR_PTR(err);
+	}
+
+	fence = kzalloc(sizeof(*fence), GFP_KERNEL);
+	if (!fence) {
+		kfree(task);
+		return ERR_PTR(-ENOMEM);
+	}
+
 	task->vm = lima_vm_get(vm);
 	task->frame = frame;
+	task->fence = &fence->base;
 
 	return task;
 }
@@ -62,11 +89,18 @@ void lima_sched_task_delete(struct lima_sched_task *task)
 {
 	int i;
 
-	if (task->fence)
-		dma_fence_put(task->fence);
+	if (task->fence) {
+		struct lima_fence *fence = to_lima_fence(task->fence);
+		if (fence->pipe)
+			dma_fence_put(task->fence);
+		else
+			kfree(fence);
+	}
 
-	for (i = 0; i < task->num_dep; i++)
-		dma_fence_put(task->dep[i]);
+	for (i = 0; i < task->num_dep; i++) {
+		if (task->dep[i])
+			dma_fence_put(task->dep[i]);
+	}
 
 	if (task->dep)
 		kfree(task->dep);
@@ -109,214 +143,224 @@ int lima_sched_task_add_dep(struct lima_sched_task *task, struct dma_fence *fenc
 	return 0;
 }
 
-int lima_sched_task_queue(struct lima_sched_pipe *pipe, struct lima_sched_task *task)
+int lima_sched_context_init(struct lima_sched_pipe *pipe,
+			    struct lima_sched_context *context)
 {
-	struct lima_fence *fence;
+	struct drm_sched_rq *rq = pipe->base.sched_rq + DRM_SCHED_PRIORITY_NORMAL;
 
-	fence = kzalloc(sizeof(*fence), GFP_KERNEL);
-	if (!fence)
-		return -ENOMEM;
-	fence->pipe = pipe;
+	spin_lock_init(&context->lock);
+	return drm_sched_entity_init(&pipe->base, &context->base, rq,
+				     LIMA_SCHED_CONTEXT_MAX_TASK, &context->guilty);
+}
 
-	spin_lock(&pipe->lock);
+void lima_sched_context_fini(struct lima_sched_pipe *pipe,
+			     struct lima_sched_context *context)
+{
+	drm_sched_entity_fini(&pipe->base, &context->base);
+}
 
-	dma_fence_init(&fence->base, &lima_fence_ops, &pipe->fence_lock,
-		       pipe->fence_context, ++pipe->fence_seqno);
-	task->fence = &fence->base;
+static uint32_t lima_sched_context_add_fence(struct lima_sched_context *context,
+					     struct dma_fence *fence)
+{
+	uint32_t seq, idx;
+	struct dma_fence *other;
 
-	/* for caller usage of the fence, otherwise pipe worker 
-	 * may consumed the fence */
-	dma_fence_get(task->fence);
+	spin_lock(&context->lock);
 
-	list_add_tail(&task->list, &pipe->queue);
+	seq = context->sequence;
+	idx = seq & (LIMA_SCHED_CONTEXT_MAX_TASK - 1);
+	other = context->fences[idx];
 
-	spin_unlock(&pipe->lock);
+	if (other) {
+		int err = dma_fence_wait(other, false);
+		if (err)
+			DRM_ERROR("Error %d waiting context fence\n", err);
+	}
 
-	wake_up(&pipe->worker_idle_wait);
-	return 0;
+	context->fences[idx] = dma_fence_get(fence);
+	context->sequence++;
+
+	spin_unlock(&context->lock);
+
+	dma_fence_put(other);
+
+	return seq;
 }
 
-static struct lima_sched_task *lima_sched_pipe_get_task(struct lima_sched_pipe *pipe)
+static struct dma_fence *lima_sched_context_get_fence(struct lima_sched_context *context,
+						      uint32_t seq)
 {
-	struct lima_sched_task *task;
+	struct dma_fence *fence;
+	int idx;
 
-	spin_lock(&pipe->lock);
-	task = list_first_entry_or_null(&pipe->queue, struct lima_sched_task, list);
-	spin_unlock(&pipe->lock);
-	return task;
-}
+	spin_lock(&context->lock);
 
-#define LIMA_WORKER_WAIT_TIMEOUT_NS 1000000000
+	/* assume no overflow */
+	if (seq >= context->sequence) {
+		fence = ERR_PTR(-EINVAL);
+		goto out;
+	}
 
-static int lima_sched_pipe_worker_wait_fence(struct dma_fence *fence)
-{
-	int ret;
-	unsigned long timeout = nsecs_to_jiffies(LIMA_WORKER_WAIT_TIMEOUT_NS);
+	if (seq + LIMA_SCHED_CONTEXT_MAX_TASK < context->sequence) {
+		fence = NULL;
+		goto out;
+	}
 
-	while (1) {
-		ret = dma_fence_wait_timeout(fence, true, timeout);
+	idx = seq & (LIMA_SCHED_CONTEXT_MAX_TASK - 1);
+	fence = dma_fence_get(context->fences[idx]);
 
-		/* interrupted by signal, may be kthread stop */
-		if (ret == -ERESTARTSYS) {
-			if (kthread_should_stop())
-				return ret;
-			else
-				continue;
-		}
+out:
+	spin_unlock(&context->lock);
 
-		if (ret < 0)
-			return ret;
+	return fence;
+}
 
-		if (!ret)
-			return -ETIMEDOUT;
+uint32_t lima_sched_context_queue_task(struct lima_sched_context *context,
+				       struct lima_sched_task *task)
+{
+	uint32_t seq = lima_sched_context_add_fence(
+		context, &task->base.s_fence->finished);
+	drm_sched_entity_push_job(&task->base, &context->base);
+	return seq;
+}
 
+int lima_sched_context_wait_fence(struct lima_sched_context *context,
+				  u32 fence, u64 timeout_ns)
+{
+	int ret;
+	struct dma_fence *f = lima_sched_context_get_fence(context, fence);
+
+	if (IS_ERR(f))
+		return PTR_ERR(f);
+	else if (!f)
 		return 0;
+
+	if (!timeout_ns)
+		ret = dma_fence_is_signaled(f) ? 0 : -EBUSY;
+	else {
+		unsigned long timeout = lima_timeout_to_jiffies(timeout_ns);
+
+		ret = dma_fence_wait_timeout(f, true, timeout);
+		if (ret == 0)
+			ret = -ETIMEDOUT;
+		else if (ret > 0)
+			ret = 0;
 	}
 
-	return 0;
+	dma_fence_put(f);
+	return ret;
 }
 
-static int lima_sched_pipe_worker_wait_busy(struct lima_sched_pipe *pipe)
+static struct dma_fence *lima_sched_dependency(struct drm_sched_job *job,
+					       struct drm_sched_entity *entity)
 {
-	int ret;
-	unsigned long timeout = nsecs_to_jiffies(LIMA_WORKER_WAIT_TIMEOUT_NS);
-
-	while (1) {
-		ret = wait_event_interruptible_timeout(
-			pipe->worker_busy_wait,
-			!pipe->worker_is_busy || kthread_should_stop(),
-			timeout);
-
-		/* interrupted by signal, may be kthread stop */
-		if (ret == -ERESTARTSYS) {
-			if (kthread_should_stop())
-				return ret;
-			else
-				continue;
-		}
+	struct lima_sched_task *task = to_lima_task(job);
+	int i;
 
-		if (ret < 0)
-			return ret;
+	for (i = 0; i < task->num_dep; i++) {
+		struct dma_fence *fence = task->dep[i];
 
-		if (!ret)
-			return -ETIMEDOUT;
+		if (!task->dep[i])
+			continue;
 
-		return 0;
+		task->dep[i] = NULL;
+
+		if (!dma_fence_is_signaled(fence))
+			return fence;
+
+		dma_fence_put(fence);
 	}
 
-	return 0;
+	return NULL;
 }
 
-static int lima_sched_pipe_worker(void *param)
+static struct dma_fence *lima_sched_run_job(struct drm_sched_job *job)
 {
-	struct lima_sched_pipe *pipe = param;
-	struct lima_sched_task *task;
+	struct lima_sched_task *task = to_lima_task(job);
+	struct lima_sched_pipe *pipe = to_lima_pipe(job->sched);
+	struct lima_fence *fence = to_lima_fence(task->fence);
+	struct dma_fence *ret;
+	int i;
 
-	while (!kthread_should_stop()) {
-		int i, ret;
+	/* after GPU reset */
+	if (job->s_fence->finished.error < 0)
+		return NULL;
 
-		wait_event_interruptible(pipe->worker_idle_wait,
-					 (task = lima_sched_pipe_get_task(pipe)) ||
-					 kthread_should_stop());
+	fence->pipe = pipe;
+	dma_fence_init(task->fence, &lima_fence_ops, &pipe->fence_lock,
+		       pipe->fence_context, ++pipe->fence_seqno);
 
-		if (!task)
-			continue;
+	/* for caller usage of the fence, otherwise irq handler 
+	 * may consume the fence before caller use it */
+	ret = dma_fence_get(task->fence);
+
+	pipe->current_task = task;
+
+	/* this is needed for MMU to work correctly, otherwise GP/PP
+	 * will hang or page fault for unknown reason after running for
+	 * a while.
+	 *
+	 * Need to investigate:
+	 * 1. is it related to TLB
+	 * 2. how much performance will be affected by L2 cache flush
+	 * 3. can we reduce the calling of this function because all
+	 *    GP/PP use the same L2 cache
+	 */
+	if (pipe->mmu[0]->ip.dev->gpu_type == GPU_MALI450) {
+		lima_l2_cache_flush(pipe->mmu[0]->ip.dev->gp->l2_cache);
+		lima_l2_cache_flush(pipe->mmu[0]->ip.dev->pp->l2_cache);
+	} else {
+		lima_l2_cache_flush(pipe->mmu[0]->ip.dev->l2_cache);
+	}
 
-		/* wait all dependent fence be signaled */
-		for (i = 0; i < task->num_dep; i++) {
-			ret = lima_sched_pipe_worker_wait_fence(task->dep[i]);
-			if (ret == -ERESTARTSYS)
-				return 0;
-			if (ret < 0) {
-				DRM_INFO("lima worker wait dep fence error %d\n", ret);
-				goto abort;
-			}
-		}
+	for (i = 0; i < pipe->num_mmu; i++)
+		lima_mmu_switch_vm(pipe->mmu[i], task->vm, false);
 
-		/* this is needed for MMU to work correctly, otherwise GP/PP
-		 * will hang or page fault for unknown reason after running for
-		 * a while.
-		 *
-		 * Need to investigate:
-		 * 1. is it related to TLB
-		 * 2. how much performance will be affected by L2 cache flush
-		 * 3. can we reduce the calling of this function because all
-		 *    GP/PP use the same L2 cache
-		 */
-		if (pipe->mmu[0]->ip.dev->gpu_type == GPU_MALI450) {
-			lima_l2_cache_flush(pipe->mmu[0]->ip.dev->gp->l2_cache);
-			lima_l2_cache_flush(pipe->mmu[0]->ip.dev->pp->l2_cache);
-		} else {
-			lima_l2_cache_flush(pipe->mmu[0]->ip.dev->l2_cache);
-		}
+	pipe->start_task(pipe->data, task);
 
-		for (i = 0; i < pipe->num_mmu; i++)
-			lima_mmu_switch_vm(pipe->mmu[i], task->vm, false);
+	return task->fence;
+}
 
-		pipe->worker_is_busy = true;
-		pipe->worker_has_error = false;
-		if (!pipe->start_task(pipe->data, task)) {
-			bool fail;
+static void lima_sched_timedout_job(struct drm_sched_job *job)
+{
+	struct lima_sched_pipe *pipe = to_lima_pipe(job->sched);
 
-			ret = lima_sched_pipe_worker_wait_busy(pipe);
-			if (ret == -ERESTARTSYS)
-				return 0;
+	kthread_park(pipe->base.thread);
+	drm_sched_hw_job_reset(&pipe->base, job);
 
-			fail = ret < 0 || pipe->worker_has_error;
-			pipe->end_task(pipe->data, fail);
+	pipe->end_task(pipe->data, true);
 
-			if (fail) {
-				DRM_INFO("lima worker wait task error\n");
-				for (i = 0; i < pipe->num_mmu; i++)
-					lima_mmu_page_fault_resume(pipe->mmu[i]);
-			}
-			else
-				dma_fence_signal(task->fence);
-		}
+	drm_sched_job_recovery(&pipe->base);
+	kthread_unpark(pipe->base.thread);
+}
 
-	abort:
-		spin_lock(&pipe->lock);
-		list_del(&task->list);
-		spin_unlock(&pipe->lock);
-		lima_sched_task_delete(task);
-		/* the only writer of this counter */
-		pipe->fence_done_seqno++;
-	}
+static void lima_sched_free_job(struct drm_sched_job *job)
+{
+	struct lima_sched_task *task = to_lima_task(job);
 
-	return 0;
+	lima_sched_task_delete(task);
 }
 
+const struct drm_sched_backend_ops lima_sched_ops = {
+	.dependency = lima_sched_dependency,
+	.run_job = lima_sched_run_job,
+	.timedout_job = lima_sched_timedout_job,
+	.free_job = lima_sched_free_job,
+};
+
 int lima_sched_pipe_init(struct lima_sched_pipe *pipe, const char *name)
 {
-	struct task_struct *worker;
+	const long timeout = msecs_to_jiffies(5000);
 
-	pipe->name = name;
-	spin_lock_init(&pipe->lock);
-	INIT_LIST_HEAD(&pipe->queue);
 	pipe->fence_context = dma_fence_context_alloc(1);
 	spin_lock_init(&pipe->fence_lock);
-	init_waitqueue_head(&pipe->worker_idle_wait);
-	init_waitqueue_head(&pipe->worker_busy_wait);
 
-	worker = kthread_run(lima_sched_pipe_worker, pipe, name);
-	if (IS_ERR(worker)) {
-		DRM_ERROR("Fail to create pipe worker for %s\n", name);
-		return PTR_ERR(worker);
-	}
-	pipe->worker = worker;
-	return 0;
+	return drm_sched_init(&pipe->base, &lima_sched_ops, 1, 0, timeout, name);
 }
 
 void lima_sched_pipe_fini(struct lima_sched_pipe *pipe)
 {
-	struct lima_sched_task *task, *tmp;
-
-	kthread_stop(pipe->worker);
-
-	list_for_each_entry_safe(task, tmp, &pipe->queue, list) {
-		list_del(&task->list);
-		lima_sched_task_delete(task);
-	}
+	drm_sched_fini(&pipe->base);
 }
 
 unsigned long lima_timeout_to_jiffies(u64 timeout_ns)
@@ -340,59 +384,14 @@ unsigned long lima_timeout_to_jiffies(u64 timeout_ns)
 	return timeout_jiffies;
 }
 
-static struct dma_fence *lima_sched_pipe_get_fence(struct lima_sched_pipe *pipe, u32 fence)
-{
-	struct lima_sched_task *task;
-	struct dma_fence *f = NULL;
-
-	spin_lock(&pipe->lock);
-	list_for_each_entry(task, &pipe->queue, list) {
-		if (task->fence->seqno < fence)
-			continue;
-
-		if (task->fence->seqno == fence) {
-			f = task->fence;
-			dma_fence_get(f);
-		}
-
-		break;
-	}
-	spin_unlock(&pipe->lock);
-
-	return f;
-}
-
-int lima_sched_pipe_wait_fence(struct lima_sched_pipe *pipe, u32 fence, u64 timeout_ns)
+void lima_sched_pipe_task_done(struct lima_sched_pipe *pipe, bool error)
 {
-	int ret = 0;
-
-	if (fence > pipe->fence_seqno)
-		return -EINVAL;
+	struct lima_sched_task *task = pipe->current_task;
 
-	if (!timeout_ns)
-		return fence <= pipe->fence_done_seqno ? 0 : -EBUSY;
-	else {
-		unsigned long timeout = lima_timeout_to_jiffies(timeout_ns);
-		struct dma_fence *f = lima_sched_pipe_get_fence(pipe, fence);
-
-		if (f) {
-			ret = dma_fence_wait_timeout(f, true, timeout);
-			if (ret == 0)
-				ret = -ETIMEDOUT;
-			else if (ret > 0)
-				ret = 0;
-			dma_fence_put(f);
-		}
-	}
-
-	return ret;
-}
+	if (!task)
+		return;
 
-void lima_sched_pipe_task_done(struct lima_sched_pipe *pipe, bool error)
-{
-	if (error)
-		pipe->worker_has_error = true;
+	pipe->end_task(pipe->data, error);
 
-	pipe->worker_is_busy = false;
-	wake_up(&pipe->worker_busy_wait);
+	dma_fence_signal(task->fence);
 }
diff --git a/drivers/gpu/drm/lima/lima_sched.h b/drivers/gpu/drm/lima/lima_sched.h
index 1c09fcc..37dc509 100644
--- a/drivers/gpu/drm/lima/lima_sched.h
+++ b/drivers/gpu/drm/lima/lima_sched.h
@@ -22,11 +22,11 @@
 #ifndef __LIMA_SCHED_H__
 #define __LIMA_SCHED_H__
 
-#include <linux/list.h>
-#include <linux/wait.h>
+#include <drm/gpu_scheduler.h>
 
 struct lima_sched_task {
-	struct list_head list;
+	struct drm_sched_job base;
+
 	struct lima_vm *vm;
 	void *frame;
 
@@ -34,43 +34,53 @@ struct lima_sched_task {
 	int num_dep;
 	int max_dep;
 
+	/* pipe fence */
 	struct dma_fence *fence;
 };
 
+#define LIMA_SCHED_CONTEXT_MAX_TASK 32
+struct lima_sched_context {
+	struct drm_sched_entity base;
+	spinlock_t lock;
+	struct dma_fence *fences[LIMA_SCHED_CONTEXT_MAX_TASK];
+	uint32_t sequence;
+	atomic_t guilty;
+};
+
 #define LIMA_SCHED_PIPE_MAX_MMU 4
 struct lima_sched_pipe {
-	const char *name;
+	struct drm_gpu_scheduler base;
 
 	u64 fence_context;
+	u32 fence_seqno;
 	spinlock_t fence_lock;
-	struct lima_mmu *mmu[LIMA_SCHED_PIPE_MAX_MMU];
-	int num_mmu;
 
-	struct task_struct *worker;
-	wait_queue_head_t worker_idle_wait;
-	wait_queue_head_t worker_busy_wait;
-	bool worker_is_busy;
-	bool worker_has_error;
+	struct lima_sched_task *current_task;
 
-	spinlock_t lock;
-	struct list_head queue;
-	u32 fence_seqno;
-
-	u32 fence_done_seqno;
+	struct lima_mmu *mmu[LIMA_SCHED_PIPE_MAX_MMU];
+	int num_mmu;
 
 	int (*start_task)(void *data, struct lima_sched_task *task);
 	int (*end_task)(void *data, bool fail);
 	void *data;
 };
 
-struct lima_sched_task *lima_sched_task_create(struct lima_vm *vm, void *frame);
+struct lima_sched_task *lima_sched_task_create(struct lima_sched_context *context,
+					       struct lima_vm *vm, void *frame);
 void lima_sched_task_delete(struct lima_sched_task *task);
 int lima_sched_task_add_dep(struct lima_sched_task *task, struct dma_fence *fence);
-int lima_sched_task_queue(struct lima_sched_pipe *pipe, struct lima_sched_task *task);
+
+int lima_sched_context_init(struct lima_sched_pipe *pipe,
+			    struct lima_sched_context *context);
+void lima_sched_context_fini(struct lima_sched_pipe *pipe,
+			     struct lima_sched_context *context);
+uint32_t lima_sched_context_queue_task(struct lima_sched_context *context,
+				       struct lima_sched_task *task);
+int lima_sched_context_wait_fence(struct lima_sched_context *context,
+				  u32 fence, u64 timeout_ns);
 
 int lima_sched_pipe_init(struct lima_sched_pipe *pipe, const char *name);
 void lima_sched_pipe_fini(struct lima_sched_pipe *pipe);
-int lima_sched_pipe_wait_fence(struct lima_sched_pipe *pipe, u32 fence, u64 timeout_ns);
 void lima_sched_pipe_task_done(struct lima_sched_pipe *pipe, bool error);
 
 #endif
