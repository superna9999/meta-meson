From 25a31cf9c3895c439fc7c2f618a0e64d67265f96 Mon Sep 17 00:00:00 2001
From: Qiang Yu <yuq825@gmail.com>
Date: Mon, 7 May 2018 15:18:38 +0800
Subject: [PATCH 132/134] drm/lima: use ttm for mm

Signed-off-by: Qiang Yu <yuq825@gmail.com>
---
 drivers/gpu/drm/lima/Kconfig          |   2 +-
 drivers/gpu/drm/lima/Makefile         |   4 +-
 drivers/gpu/drm/lima/lima_device.c    |  28 +-
 drivers/gpu/drm/lima/lima_device.h    |  19 +-
 drivers/gpu/drm/lima/lima_drv.c       |  18 +-
 drivers/gpu/drm/lima/lima_drv.h       |  11 +-
 drivers/gpu/drm/lima/lima_gem.c       | 471 ++++++++++------------------------
 drivers/gpu/drm/lima/lima_gem.h       |  46 ----
 drivers/gpu/drm/lima/lima_gem_prime.c |  70 ++---
 drivers/gpu/drm/lima/lima_mmu.c       |   7 +-
 drivers/gpu/drm/lima/lima_object.c    | 120 +++++++++
 drivers/gpu/drm/lima/lima_object.h    |  87 +++++++
 drivers/gpu/drm/lima/lima_ttm.c       | 409 +++++++++++++++++++++++++++++
 drivers/gpu/drm/lima/lima_ttm.h       |  44 ++++
 drivers/gpu/drm/lima/lima_vm.c        | 261 +++++++++++++------
 drivers/gpu/drm/lima/lima_vm.h        |  34 +--
 16 files changed, 1061 insertions(+), 570 deletions(-)
 create mode 100644 drivers/gpu/drm/lima/lima_object.c
 create mode 100644 drivers/gpu/drm/lima/lima_object.h
 create mode 100644 drivers/gpu/drm/lima/lima_ttm.c
 create mode 100644 drivers/gpu/drm/lima/lima_ttm.h

diff --git a/drivers/gpu/drm/lima/Kconfig b/drivers/gpu/drm/lima/Kconfig
index bb72220..4ce9ac2 100644
--- a/drivers/gpu/drm/lima/Kconfig
+++ b/drivers/gpu/drm/lima/Kconfig
@@ -3,7 +3,7 @@ config DRM_LIMA
        tristate "LIMA (DRM support for ARM Mali 400/450 GPU)"
        depends on DRM
        depends on ARCH_SUNXI || ARCH_ROCKCHIP || ARCH_EXYNOS || ARCH_MESON
-       depends on (ARM && !ARM_LPAE) || ZONE_DMA32 || ZONE_DMA
        select DRM_SCHED
+       select DRM_TTM
        help
          DRM driver for ARM Mali 400/450 GPUs.
diff --git a/drivers/gpu/drm/lima/Makefile b/drivers/gpu/drm/lima/Makefile
index a5ecdb0..0a1d660 100644
--- a/drivers/gpu/drm/lima/Makefile
+++ b/drivers/gpu/drm/lima/Makefile
@@ -12,6 +12,8 @@ lima-y := \
 	lima_ctx.o \
 	lima_gem_prime.o \
 	lima_dlbu.o \
-	lima_bcast.o
+	lima_bcast.o \
+	lima_ttm.o \
+	lima_object.o
 
 obj-$(CONFIG_DRM_LIMA) += lima.o
diff --git a/drivers/gpu/drm/lima/lima_device.c b/drivers/gpu/drm/lima/lima_device.c
index d6ef632..74cb315 100644
--- a/drivers/gpu/drm/lima/lima_device.c
+++ b/drivers/gpu/drm/lima/lima_device.c
@@ -310,10 +310,14 @@ int lima_device_init(struct lima_device *ldev)
 		goto err_out0;
 	}
 
+	err = lima_ttm_init(ldev);
+	if (err)
+		goto err_out1;
+
 	ldev->empty_vm = lima_vm_create(ldev);
 	if (!ldev->empty_vm) {
 		err = -ENOMEM;
-		goto err_out1;
+		goto err_out2;
 	}
 
 	ldev->va_start = 0;
@@ -324,7 +328,7 @@ int lima_device_init(struct lima_device *ldev)
 			&ldev->dlbu_dma, GFP_KERNEL);
 		if (!ldev->dlbu_cpu) {
 			err = -ENOMEM;
-			goto err_out2;
+			goto err_out3;
 		}
 	}
 	else
@@ -335,22 +339,22 @@ int lima_device_init(struct lima_device *ldev)
 	if (IS_ERR(ldev->iomem)) {
 		dev_err(ldev->dev, "fail to ioremap iomem\n");
 	        err = PTR_ERR(ldev->iomem);
-		goto err_out3;
+		goto err_out4;
 	}
 
 	for (i = 0; i < lima_ip_num; i++) {
 		err = lima_init_ip(ldev, i);
 		if (err)
-			goto err_out4;
+			goto err_out5;
 	}
 
 	err = lima_init_gp_pipe(ldev);
 	if (err)
-		goto err_out4;
+		goto err_out5;
 
 	err = lima_init_pp_pipe(ldev);
 	if (err)
-		goto err_out5;
+		goto err_out6;
 
 	if (ldev->id == lima_gpu_mali450) {
 		lima_dlbu_enable(ldev);
@@ -359,17 +363,19 @@ int lima_device_init(struct lima_device *ldev)
 
 	return 0;
 
-err_out5:
+err_out6:
 	lima_fini_gp_pipe(ldev);
-err_out4:
+err_out5:
 	while (--i >= 0)
 		lima_fini_ip(ldev, i);
-err_out3:
+err_out4:
 	if (ldev->dlbu_cpu)
 		dma_free_wc(ldev->dev, LIMA_PAGE_SIZE,
 			    ldev->dlbu_cpu, ldev->dlbu_dma);
-err_out2:
+err_out3:
 	lima_vm_put(ldev->empty_vm);
+err_out2:
+	lima_ttm_fini(ldev);
 err_out1:
 	lima_regulator_fini(ldev);
 err_out0:
@@ -393,6 +399,8 @@ void lima_device_fini(struct lima_device *ldev)
 
 	lima_vm_put(ldev->empty_vm);
 
+	lima_ttm_fini(ldev);
+
 	lima_regulator_fini(ldev);
 
 	lima_clk_fini(ldev);
diff --git a/drivers/gpu/drm/lima/lima_device.h b/drivers/gpu/drm/lima/lima_device.h
index ec0e0c6..7f0d5f2 100644
--- a/drivers/gpu/drm/lima/lima_device.h
+++ b/drivers/gpu/drm/lima/lima_device.h
@@ -22,10 +22,13 @@
 #ifndef __LIMA_DEVICE_H__
 #define __LIMA_DEVICE_H__
 
+#include <drm/drm_device.h>
+
 #include "lima_sched.h"
+#include "lima_ttm.h"
 
 enum lima_gpu_id {
-        lima_gpu_mali400 = 0,
+	lima_gpu_mali400 = 0,
 	lima_gpu_mali450,
 	lima_gpu_num,
 };
@@ -103,6 +106,8 @@ struct lima_device {
 	struct lima_ip ip[lima_ip_num];
 	struct lima_sched_pipe pipe[lima_pipe_num];
 
+	struct lima_mman mman;
+
 	struct lima_vm *empty_vm;
 	uint64_t va_start;
 	uint64_t va_end;
@@ -111,6 +116,18 @@ struct lima_device {
 	dma_addr_t dlbu_dma;
 };
 
+static inline struct lima_device *
+to_lima_dev(struct drm_device *dev)
+{
+	return dev->dev_private;
+}
+
+static inline struct lima_device *
+ttm_to_lima_dev(struct ttm_bo_device *dev)
+{
+	return container_of(dev, struct lima_device, mman.bdev);
+}
+
 int lima_device_init(struct lima_device *ldev);
 void lima_device_fini(struct lima_device *ldev);
 
diff --git a/drivers/gpu/drm/lima/lima_drv.c b/drivers/gpu/drm/lima/lima_drv.c
index 61b5557..e83385f 100644
--- a/drivers/gpu/drm/lima/lima_drv.c
+++ b/drivers/gpu/drm/lima/lima_drv.c
@@ -33,6 +33,7 @@
 
 int lima_sched_timeout_ms = 0;
 int lima_sched_max_tasks = 32;
+int lima_max_mem = -1;
 
 MODULE_PARM_DESC(sched_timeout_ms, "task run timeout in ms (0 = no timeout (default))");
 module_param_named(sched_timeout_ms, lima_sched_timeout_ms, int, 0444);
@@ -40,11 +41,8 @@ module_param_named(sched_timeout_ms, lima_sched_timeout_ms, int, 0444);
 MODULE_PARM_DESC(sched_max_tasks, "max queued task num in a context (default 32)");
 module_param_named(sched_max_tasks, lima_sched_max_tasks, int, 0444);
 
-
-static inline struct lima_device *to_lima_dev(struct drm_device *dev)
-{
-	return dev->dev_private;
-}
+MODULE_PARM_DESC(max_mem, "Max memory size in MB can be used (<0 = auto)");
+module_param_named(max_mem, lima_max_mem, int, 0444);
 
 static int lima_ioctl_info(struct drm_device *dev, void *data, struct drm_file *file)
 {
@@ -120,7 +118,7 @@ static int lima_ioctl_gem_submit(struct drm_device *dev, void *data, struct drm_
 	if (args->frame_size != pipe->frame_size)
 		return -EINVAL;
 
-	size = args->nr_bos * (sizeof(*submit.bos) + sizeof(*submit.lbos));
+	size = args->nr_bos * (sizeof(*submit.bos) + sizeof(*submit.vbs));
 	bos = kzalloc(size, GFP_KERNEL);
 	if (!bos)
 		return -ENOMEM;
@@ -155,7 +153,7 @@ static int lima_ioctl_gem_submit(struct drm_device *dev, void *data, struct drm_
 
 	submit.pipe = args->pipe;
 	submit.bos = bos;
-	submit.lbos = (void *)bos + size;
+	submit.vbs = (void *)bos + size;
 	submit.nr_bos = args->nr_bos;
 	submit.task = task;
 	submit.ctx = ctx;
@@ -267,8 +265,6 @@ static const struct drm_ioctl_desc lima_drm_driver_ioctls[] = {
 	DRM_IOCTL_DEF_DRV(LIMA_CTX, lima_ioctl_ctx, DRM_AUTH|DRM_RENDER_ALLOW),
 };
 
-extern const struct vm_operations_struct lima_gem_vm_ops;
-
 static const struct file_operations lima_drm_driver_fops = {
 	.owner              = THIS_MODULE,
 	.open               = drm_open,
@@ -290,7 +286,6 @@ static struct drm_driver lima_drm_driver = {
 	.gem_free_object_unlocked = lima_gem_free_object,
 	.gem_open_object    = lima_gem_object_open,
 	.gem_close_object   = lima_gem_object_close,
-	.gem_vm_ops         = &lima_gem_vm_ops,
 	.name               = "lima",
 	.desc               = "lima DRM",
 	.date               = "20170325",
@@ -387,6 +382,9 @@ static void lima_check_module_param(void)
 		lima_sched_max_tasks = 4;
 	else
 		lima_sched_max_tasks = roundup_pow_of_two(lima_sched_max_tasks);
+
+	if (lima_max_mem < 32)
+		lima_max_mem = -1;
 }
 
 static int __init lima_init(void)
diff --git a/drivers/gpu/drm/lima/lima_drv.h b/drivers/gpu/drm/lima/lima_drv.h
index 29e3c43..3d6d52a 100644
--- a/drivers/gpu/drm/lima/lima_drv.h
+++ b/drivers/gpu/drm/lima/lima_drv.h
@@ -23,11 +23,13 @@
 #define __LIMA_DRV_H__
 
 #include <drm/drmP.h>
+#include <drm/ttm/ttm_execbuf_util.h>
 
 #include "lima_ctx.h"
 
 extern int lima_sched_timeout_ms;
 extern int lima_sched_max_tasks;
+extern int lima_max_mem;
 
 struct lima_vm;
 struct lima_bo;
@@ -35,6 +37,8 @@ struct lima_sched_task;
 
 struct drm_lima_gem_submit_bo;
 
+#define DRM_FILE_PAGE_OFFSET (0x100000000ULL >> PAGE_SHIFT)
+
 struct lima_drm_priv {
 	struct lima_vm *vm;
 	struct lima_ctx_mgr ctx_mgr;
@@ -45,9 +49,14 @@ struct lima_submit {
 	int pipe;
 
 	struct drm_lima_gem_submit_bo *bos;
-	struct lima_bo **lbos;
+	struct ttm_validate_buffer *vbs;
 	u32 nr_bos;
 
+	struct ttm_validate_buffer vm_pd_vb;
+	struct ww_acquire_ctx ticket;
+	struct list_head duplicates;
+	struct list_head validated;
+
 	struct lima_sched_task *task;
 
 	uint32_t fence;
diff --git a/drivers/gpu/drm/lima/lima_gem.c b/drivers/gpu/drm/lima/lima_gem.c
index 1bface5..00fd6be 100644
--- a/drivers/gpu/drm/lima/lima_gem.c
+++ b/drivers/gpu/drm/lima/lima_gem.c
@@ -29,129 +29,25 @@
 #include "lima_drv.h"
 #include "lima_gem.h"
 #include "lima_vm.h"
-
-static void lima_bo_shmem_release(struct lima_bo *bo)
-{
-	if (bo->pages_dma_addr) {
-		int i, npages = bo->gem.size >> PAGE_SHIFT;
-
-		for (i = 0; i < npages; i++) {
-			if (bo->pages_dma_addr[i])
-				dma_unmap_page(bo->gem.dev->dev,
-					       bo->pages_dma_addr[i],
-					       PAGE_SIZE, DMA_BIDIRECTIONAL);
-		}
-
-		kfree(bo->pages_dma_addr);
-	}
-
-	if (bo->pages)
-		drm_gem_put_pages(&bo->gem, bo->pages, true, true);
-}
-
-static int lima_bo_shmem_mmap(struct lima_bo *bo, struct vm_area_struct *vma)
-{
-	pgprot_t prot = vm_get_page_prot(vma->vm_flags);
-
-	/* TODO: is it better to just remap_pfn_range all the pages here? */
-
-	vma->vm_flags |= VM_MIXEDMAP;
-	vma->vm_flags &= ~VM_PFNMAP;
-
-	vma->vm_page_prot = pgprot_writecombine(prot);
-	return 0;
-}
-
-static struct lima_bo_ops lima_bo_shmem_ops = {
-	.release = lima_bo_shmem_release,
-	.mmap = lima_bo_shmem_mmap,
-};
-
-struct lima_bo *lima_gem_create_bo(struct drm_device *dev, u32 size, u32 flags)
-{
-	int err;
-	struct lima_bo *bo;
-
-	size = PAGE_ALIGN(size);
-
-	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
-	if (!bo)
-		return ERR_PTR(-ENOMEM);
-
-	mutex_init(&bo->lock);
-	INIT_LIST_HEAD(&bo->va);
-	reservation_object_init(&bo->_resv);
-
-	err = drm_gem_object_init(dev, &bo->gem, size);
-	if (err)
-		goto err_out0;
-
-	return bo;
-
-err_out0:
-	kfree(bo);
-	return ERR_PTR(err);
-}
+#include "lima_object.h"
 
 int lima_gem_create_handle(struct drm_device *dev, struct drm_file *file,
 			   u32 size, u32 flags, u32 *handle)
 {
-	int err, npages, i;
+	int err;
 	struct lima_bo *bo;
-	gfp_t mask;
+	struct lima_device *ldev = to_lima_dev(dev);
 
-	bo = lima_gem_create_bo(dev, size, flags);
+	bo = lima_bo_create(ldev, size, flags, ttm_bo_type_device, NULL, NULL);
 	if (IS_ERR(bo))
 		return PTR_ERR(bo);
 
-#if defined(CONFIG_ARM) && !defined(CONFIG_ARM_LPAE)
-	mask = GFP_HIGHUSER;
-#elif defined(CONFIG_ZONE_DMA32)
-	mask = GFP_DMA32;
-#else
-	mask = GFP_DMA;
-#endif
-
-	bo->type = lima_bo_type_shmem;
-	bo->ops = &lima_bo_shmem_ops;
-
-	mapping_set_gfp_mask(bo->gem.filp->f_mapping, mask);
-	bo->pages = drm_gem_get_pages(&bo->gem);
-	if (IS_ERR(bo->pages)) {
-		err = PTR_ERR(bo->pages);
-		bo->pages = NULL;
-		goto err_out;
-	}
-
-	npages = bo->gem.size >> PAGE_SHIFT;
-	bo->pages_dma_addr = kzalloc(npages * sizeof(dma_addr_t), GFP_KERNEL);
-	if (!bo->pages_dma_addr) {
-		err = -ENOMEM;
-		goto err_out;
-	}
-
-	for (i = 0; i < npages; i++) {
-		dma_addr_t addr = dma_map_page(dev->dev, bo->pages[i], 0,
-					       PAGE_SIZE, DMA_BIDIRECTIONAL);
-		if (dma_mapping_error(dev->dev, addr)) {
-			err = -EFAULT;
-			goto err_out;
-		}
-		bo->pages_dma_addr[i] = addr;
-	}
-
-	bo->resv = &bo->_resv;
-
 	err = drm_gem_handle_create(file, &bo->gem, handle);
 
 	/* drop reference from allocate - handle holds it now */
-	drm_gem_object_unreference_unlocked(&bo->gem);
+	drm_gem_object_put_unlocked(&bo->gem);
 
 	return err;
-
-err_out:
-	lima_gem_free_object(&bo->gem);
-	return err;
 }
 
 void lima_gem_free_object(struct drm_gem_object *obj)
@@ -161,25 +57,7 @@ void lima_gem_free_object(struct drm_gem_object *obj)
 	if (!list_empty(&bo->va))
 		dev_err(obj->dev->dev, "lima gem free bo still has va\n");
 
-        bo->ops->release(bo);
-
-	reservation_object_fini(&bo->_resv);
-	drm_gem_object_release(obj);
-	kfree(bo);
-}
-
-static struct lima_bo_va *lima_gem_find_bo_va(struct lima_bo *bo, struct lima_vm *vm)
-{
-	struct lima_bo_va *bo_va, *ret = NULL;
-
-	list_for_each_entry(bo_va, &bo->va, list) {
-		if (bo_va->vm == vm) {
-			ret = bo_va;
-			break;
-		}
-	}
-
-	return ret;
+	lima_bo_unref(bo);
 }
 
 int lima_gem_object_open(struct drm_gem_object *obj, struct drm_file *file)
@@ -187,145 +65,95 @@ int lima_gem_object_open(struct drm_gem_object *obj, struct drm_file *file)
 	struct lima_bo *bo = to_lima_bo(obj);
 	struct lima_drm_priv *priv = to_lima_drm_priv(file);
 	struct lima_vm *vm = priv->vm;
-	struct lima_bo_va *bo_va;
-	int err = 0;
-
-	mutex_lock(&bo->lock);
-
-	bo_va = lima_gem_find_bo_va(bo, vm);
-	if (bo_va)
-		bo_va->ref_count++;
-	else {
-		bo_va = kmalloc(sizeof(*bo_va), GFP_KERNEL);
-		if (!bo_va) {
-			err = -ENOMEM;
-			goto out;
-		}
+	int err;
 
-		bo_va->vm = vm;
-		bo_va->ref_count = 1;
-		INIT_LIST_HEAD(&bo_va->mapping);
-		list_add_tail(&bo_va->list, &bo->va);
-	}
+	err = lima_bo_reserve(bo, true);
+	if (err)
+		return err;
 
-out:
-	mutex_unlock(&bo->lock);
+	err = lima_vm_bo_add(vm, bo);
+
+	lima_bo_unreserve(bo);
 	return err;
 }
 
 void lima_gem_object_close(struct drm_gem_object *obj, struct drm_file *file)
 {
 	struct lima_bo *bo = to_lima_bo(obj);
+	struct lima_device *dev = to_lima_dev(obj->dev);
 	struct lima_drm_priv *priv = to_lima_drm_priv(file);
 	struct lima_vm *vm = priv->vm;
-	struct lima_bo_va *bo_va;
 
-	mutex_lock(&bo->lock);
+	LIST_HEAD(list);
+	struct ttm_validate_buffer tv_bo, tv_pd;
+	struct ww_acquire_ctx ticket;
+	int r;
 
-	bo_va = lima_gem_find_bo_va(bo, vm);
-	BUG_ON(!bo_va);
+	tv_bo.bo = &bo->tbo;
+	tv_bo.shared = true;
+	list_add(&tv_bo.head, &list);
 
-	if (--bo_va->ref_count == 0) {
-		struct lima_bo_va_mapping *mapping, *tmp;
-		list_for_each_entry_safe(mapping, tmp, &bo_va->mapping, list) {
-			lima_vm_unmap(vm, mapping);
-			list_del(&mapping->list);
-			kfree(mapping);
-		}
-		list_del(&bo_va->list);
-		kfree(bo_va);
+	tv_pd.bo = &vm->pd->tbo;
+	tv_pd.shared = true;
+	list_add(&tv_pd.head, &list);
+
+	r = ttm_eu_reserve_buffers(&ticket, &list, false, NULL);
+	if (r) {
+		dev_err(dev->dev, "leeking bo va because we "
+			"fail to reserve bo (%d)\n", r);
+		return;
 	}
 
-	mutex_unlock(&bo->lock);
+	lima_vm_bo_del(vm, bo);
+
+	ttm_eu_backoff_reservation(&ticket, &list);
 }
 
 int lima_gem_mmap_offset(struct drm_file *file, u32 handle, u64 *offset)
 {
-	int err;
 	struct drm_gem_object *obj;
+	struct lima_bo *bo;
 
 	obj = drm_gem_object_lookup(file, handle);
 	if (!obj)
 		return -ENOENT;
 
-	err = drm_gem_create_mmap_offset(obj);
-	if (!err)
-		*offset = drm_vma_node_offset_addr(&obj->vma_node);
+	bo = to_lima_bo(obj);
+	*offset = drm_vma_node_offset_addr(&bo->tbo.vma_node);
 
-	drm_gem_object_unreference_unlocked(obj);
-	return err;
+	drm_gem_object_put_unlocked(obj);
+	return 0;
 }
 
 int lima_gem_mmap(struct file *filp, struct vm_area_struct *vma)
 {
-	int err;
-	struct lima_bo *bo;
-
-	err = drm_gem_mmap(filp, vma);
-	if (err)
-		return err;
-
-	bo = to_lima_bo(vma->vm_private_data);
-
-	err = bo->ops->mmap(bo, vma);
-	if (err)
-		drm_gem_vm_close(vma);
-
-	return err;
-}
-
-static int lima_gem_fault(struct vm_fault *vmf)
-{
-	struct vm_area_struct *vma = vmf->vma;
-	struct lima_bo *bo = to_lima_bo(vma->vm_private_data);
-	unsigned long offset;
-	int err;
-
-	if (!bo->pages)
-		return VM_FAULT_SIGBUS;
+	struct drm_file *file_priv;
+	struct lima_device *dev;
 
-	offset = (vmf->address - vma->vm_start) >> PAGE_SHIFT;
+	if (unlikely(vma->vm_pgoff < DRM_FILE_PAGE_OFFSET))
+		return -EINVAL;
 
-	/* TODO:
-	 *   1. use vm_insert_pfn instead of vm_insert_page which
-	 *     will flush dcache (already done when alloc) so is
-	 *     slower than vm_insert_pfn
-	 *   2. insert more pages at once to reduce page fault as
-	 *     GPU buffer will be accessed by CPU continuously and
-	 *     in big blocks
-	 */
-	err = vm_insert_page(vma, vmf->address, bo->pages[offset]);
-	switch (err) {
-	case -EAGAIN:
-	case 0:
-	case -ERESTARTSYS:
-	case -EINTR:
-	case -EBUSY:
-		return VM_FAULT_NOPAGE;
-
-	case -ENOMEM:
-		return VM_FAULT_OOM;
-	}
+	file_priv = filp->private_data;
+	dev = file_priv->minor->dev->dev_private;
+	if (dev == NULL)
+		return -EINVAL;
 
-	return VM_FAULT_SIGBUS;
+	return ttm_bo_mmap(filp, vma, &dev->mman.bdev);
 }
 
-const struct vm_operations_struct lima_gem_vm_ops = {
-	.fault = lima_gem_fault,
-	.open = drm_gem_vm_open,
-	.close = drm_gem_vm_close,
-};
-
 int lima_gem_va_map(struct drm_file *file, u32 handle, u32 flags, u32 va)
 {
 	struct lima_drm_priv *priv = to_lima_drm_priv(file);
 	struct lima_vm *vm = priv->vm;
 	struct drm_gem_object *obj;
 	struct lima_bo *bo;
-	struct lima_bo_va *bo_va;
-	struct lima_bo_va_mapping *mapping;
+	struct lima_device *dev;
 	int err;
 
+	LIST_HEAD(list);
+	struct ttm_validate_buffer tv_bo, tv_pd;
+	struct ww_acquire_ctx ticket;
+
 	if (!PAGE_ALIGNED(va))
 		return -EINVAL;
 
@@ -334,43 +162,31 @@ int lima_gem_va_map(struct drm_file *file, u32 handle, u32 flags, u32 va)
 		return -ENOENT;
 
 	bo = to_lima_bo(obj);
+	dev = to_lima_dev(obj->dev);
 
 	/* carefully handle overflow when calculate range */
-	if (va < vm->dev->va_start || vm->dev->va_end - obj->size < va) {
+	if (va < dev->va_start || dev->va_end - obj->size < va) {
 		err = -EINVAL;
-		goto err_out0;
+		goto out;
 	}
 
-	mapping = kmalloc(sizeof(*mapping), GFP_KERNEL);
-	if (!mapping) {
-		err = -ENOMEM;
-		goto err_out0;
-	}
-
-	mapping->start = va;
-	mapping->last = va + obj->size - 1;
-
-	mutex_lock(&bo->lock);
+	tv_bo.bo = &bo->tbo;
+	tv_bo.shared = true;
+	list_add(&tv_bo.head, &list);
 
-	bo_va = lima_gem_find_bo_va(bo, vm);
-	BUG_ON(!bo_va);
+	tv_pd.bo = &vm->pd->tbo;
+	tv_pd.shared = true;
+	list_add(&tv_pd.head, &list);
 
-	err = lima_vm_map(vm, bo->pages_dma_addr, mapping);
+	err = ttm_eu_reserve_buffers(&ticket, &list, false, NULL);
 	if (err)
-		goto err_out1;
+		goto out;
 
-	list_add_tail(&mapping->list, &bo_va->mapping);
+	err = lima_vm_bo_map(vm, bo, va);
 
-	mutex_unlock(&bo->lock);
-
-	drm_gem_object_unreference_unlocked(obj);
-	return 0;
-
-err_out1:
-	mutex_unlock(&bo->lock);
-	kfree(mapping);
-err_out0:
-	drm_gem_object_unreference_unlocked(obj);
+	ttm_eu_backoff_reservation(&ticket, &list);
+out:
+	drm_gem_object_put_unlocked(obj);
 	return err;
 }
 
@@ -380,8 +196,14 @@ int lima_gem_va_unmap(struct drm_file *file, u32 handle, u32 va)
 	struct lima_vm *vm = priv->vm;
 	struct drm_gem_object *obj;
 	struct lima_bo *bo;
-	struct lima_bo_va *bo_va;
-	struct lima_bo_va_mapping *mapping;
+	int err;
+
+	LIST_HEAD(list);
+	struct ttm_validate_buffer tv_bo, tv_pd;
+	struct ww_acquire_ctx ticket;
+
+	if (!PAGE_ALIGNED(va))
+		return -EINVAL;
 
 	obj = drm_gem_object_lookup(file, handle);
 	if (!obj)
@@ -389,68 +211,24 @@ int lima_gem_va_unmap(struct drm_file *file, u32 handle, u32 va)
 
 	bo = to_lima_bo(obj);
 
-	mutex_lock(&bo->lock);
-
-	bo_va = lima_gem_find_bo_va(bo, vm);
-	BUG_ON(!bo_va);
-
-	list_for_each_entry(mapping, &bo_va->mapping, list) {
-		if (mapping->start == va) {
-			lima_vm_unmap(vm, mapping);
-			list_del(&mapping->list);
-			kfree(mapping);
-			break;
-		}
-	}
+	tv_bo.bo = &bo->tbo;
+	tv_bo.shared = true;
+	list_add(&tv_bo.head, &list);
 
-	mutex_unlock(&bo->lock);
+	tv_pd.bo = &vm->pd->tbo;
+	tv_pd.shared = true;
+	list_add(&tv_pd.head, &list);
 
-	drm_gem_object_unreference_unlocked(obj);
-	return 0;
-}
-
-static int lima_gem_lock_bos(struct lima_bo **bos, u32 nr_bos,
-			     struct ww_acquire_ctx *ctx)
-{
-        int i, ret = 0, contended, slow_locked = -1;
-
-	ww_acquire_init(ctx, &reservation_ww_class);
-
-retry:
-	for (i = 0; i < nr_bos; i++) {
-		if (i == slow_locked) {
-			slow_locked = -1;
-			continue;
-		}
-
-		ret = ww_mutex_lock_interruptible(&bos[i]->resv->lock, ctx);
-		if (ret < 0) {
-			contended = i;
-			goto err;
-		}
-	}
-
-	ww_acquire_done(ctx);
-	return 0;
-
-err:
-	for (i--; i >= 0; i--)
-		ww_mutex_unlock(&bos[i]->resv->lock);
-
-	if (slow_locked >= 0)
-		ww_mutex_unlock(&bos[slow_locked]->resv->lock);
+	err = ttm_eu_reserve_buffers(&ticket, &list, false, NULL);
+	if (err)
+		goto out;
 
-	if (ret == -EDEADLK) {
-		/* we lost out in a seqno race, lock and retry.. */
-		ret = ww_mutex_lock_slow_interruptible(&bos[contended]->resv->lock, ctx);
-		if (!ret) {
-			slow_locked = contended;
-			goto retry;
-		}
-	}
-	ww_acquire_fini(ctx);
+	err = lima_vm_bo_unmap(vm, bo, va);
 
-	return ret;
+	ttm_eu_backoff_reservation(&ticket, &list);
+out:
+	drm_gem_object_put_unlocked(obj);
+	return err;
 }
 
 static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo, bool write)
@@ -461,12 +239,12 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo, bo
 
 	if (write) {
 		struct reservation_object_list *fobj =
-			reservation_object_get_list(bo->resv);
+			reservation_object_get_list(bo->tbo.resv);
 
 		if (fobj && fobj->shared_count > 0) {
 			for (i = 0; i < fobj->shared_count; i++) {
 				f = rcu_dereference_protected(
-					fobj->shared[i], reservation_object_held(bo->resv));
+					fobj->shared[i], reservation_object_held(bo->tbo.resv));
 				if (f->context != context) {
 					err = lima_sched_task_add_dep(task, f);
 					if (err)
@@ -476,7 +254,7 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo, bo
 		}
 	}
 
-	f = reservation_object_get_excl(bo->resv);
+	f = reservation_object_get_excl(bo->tbo.resv);
 	if (f) {
 		err = lima_sched_task_add_dep(task, f);
 		if (err)
@@ -484,7 +262,7 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo, bo
 	}
 
 	if (!write) {
-		err = reservation_object_reserve_shared(bo->resv);
+		err = reservation_object_reserve_shared(bo->tbo.resv);
 		if (err)
 			return err;
 	}
@@ -495,58 +273,69 @@ static int lima_gem_sync_bo(struct lima_sched_task *task, struct lima_bo *bo, bo
 int lima_gem_submit(struct drm_file *file, struct lima_submit *submit)
 {
 	int i, err = 0;
-	struct ww_acquire_ctx ctx;
 	struct lima_drm_priv *priv = to_lima_drm_priv(file);
+	struct lima_vm *vm = priv->vm;
+
+	INIT_LIST_HEAD(&submit->validated);
+	INIT_LIST_HEAD(&submit->duplicates);
 
 	for (i = 0; i < submit->nr_bos; i++) {
 		struct drm_gem_object *obj;
+		struct drm_lima_gem_submit_bo *bo = submit->bos + i;
+		struct ttm_validate_buffer *vb = submit->vbs + i;
 
-		obj = drm_gem_object_lookup(file, submit->bos[i].handle);
+		obj = drm_gem_object_lookup(file, bo->handle);
 		if (!obj) {
 			err = -ENOENT;
 			goto out0;
 		}
-		submit->lbos[i] = to_lima_bo(obj);
+
+		vb->bo = &to_lima_bo(obj)->tbo;
+		vb->shared = !(bo->flags & LIMA_SUBMIT_BO_WRITE);
+		list_add_tail(&vb->head, &submit->validated);
 	}
 
-	err = lima_gem_lock_bos(submit->lbos, submit->nr_bos, &ctx);
+	submit->vm_pd_vb.bo = &vm->pd->tbo;
+	submit->vm_pd_vb.shared = true;
+	list_add(&submit->vm_pd_vb.head, &submit->validated);
+
+	err = ttm_eu_reserve_buffers(&submit->ticket, &submit->validated,
+				     true, &submit->duplicates);
 	if (err)
 		goto out0;
 
 	err = lima_sched_task_init(
-		submit->task, submit->ctx->context + submit->pipe, priv->vm);
+		submit->task, submit->ctx->context + submit->pipe, vm);
 	if (err)
 		goto out1;
 
 	for (i = 0; i < submit->nr_bos; i++) {
-		err = lima_gem_sync_bo(submit->task, submit->lbos[i],
-				       submit->bos[i].flags & LIMA_SUBMIT_BO_WRITE);
+		struct ttm_validate_buffer *vb = submit->vbs + i;
+		struct lima_bo *bo = ttm_to_lima_bo(vb->bo);
+		err = lima_gem_sync_bo(submit->task, bo, !vb->shared);
 		if (err)
 			goto out2;
 	}
 
-	for (i = 0; i < submit->nr_bos; i++) {
-		if (submit->bos[i].flags & LIMA_SUBMIT_BO_WRITE)
-			reservation_object_add_excl_fence(
-				submit->lbos[i]->resv, &submit->task->base.s_fence->finished);
-		else
-			reservation_object_add_shared_fence(
-				submit->lbos[i]->resv, &submit->task->base.s_fence->finished);
-	}
-
 	submit->fence = lima_sched_context_queue_task(
 		submit->ctx->context + submit->pipe, submit->task, &submit->done);
 
+	ttm_eu_fence_buffer_objects(&submit->ticket, &submit->validated,
+				    &submit->task->base.s_fence->finished);
+
 out2:
 	if (err)
 		lima_sched_task_fini(submit->task);
 out1:
-	for (i = 0; i < submit->nr_bos; i++)
-		ww_mutex_unlock(&submit->lbos[i]->resv->lock);
-	ww_acquire_fini(&ctx);
+        if (err)
+		ttm_eu_backoff_reservation(&submit->ticket, &submit->validated);
 out0:
-	for (i = 0; i < submit->nr_bos && submit->lbos[i]; i++)
-		drm_gem_object_unreference_unlocked(&submit->lbos[i]->gem);
+	for (i = 0; i < submit->nr_bos; i++) {
+		struct ttm_validate_buffer *vb = submit->vbs + i;
+		if (!vb->bo)
+			break;
+		drm_gem_object_put_unlocked(&ttm_to_lima_bo(vb->bo)->gem);
+	}
 	return err;
 }
 
@@ -566,15 +355,21 @@ int lima_gem_wait(struct drm_file *file, u32 handle, u32 op, u64 timeout_ns)
 
 	timeout = timeout_ns ? lima_timeout_to_jiffies(timeout_ns) : 0;
 
+	ret = lima_bo_reserve(bo, true);
+	if (ret)
+		goto out;
+
 	/* must use long for result check because in 64bit arch int
 	 * will overflow if timeout is too large and get <0 result
 	 */
-	ret = reservation_object_wait_timeout_rcu(bo->resv, write, true, timeout);
+	ret = reservation_object_wait_timeout_rcu(bo->tbo.resv, write, true, timeout);
 	if (ret == 0)
 		ret = timeout ? -ETIMEDOUT : -EBUSY;
 	else if (ret > 0)
 		ret = 0;
 
-	drm_gem_object_unreference_unlocked(obj);
+	lima_bo_unreserve(bo);
+out:
+	drm_gem_object_put_unlocked(obj);
 	return ret;
 }
diff --git a/drivers/gpu/drm/lima/lima_gem.h b/drivers/gpu/drm/lima/lima_gem.h
index 1614066..dc44589 100644
--- a/drivers/gpu/drm/lima/lima_gem.h
+++ b/drivers/gpu/drm/lima/lima_gem.h
@@ -22,54 +22,8 @@
 #ifndef __LIMA_GEM_H__
 #define __LIMA_GEM_H__
 
-#include <drm/drm_gem.h>
-#include <linux/reservation.h>
-
 struct lima_bo;
 struct lima_submit;
-struct lima_vm;
-
-struct lima_bo_va {
-	struct list_head list;
-	unsigned ref_count;
-
-	struct list_head mapping;
-
-	struct lima_vm *vm;
-};
-
-struct lima_bo_ops {
-	void (*release)(struct lima_bo *);
-	int (*mmap)(struct lima_bo *, struct vm_area_struct *);
-};
-
-struct lima_bo {
-	struct drm_gem_object gem;
-
-	enum lima_bo_type {
-		lima_bo_type_shmem,
-		lima_bo_type_dma_buf,
-	} type;
-
-	struct page **pages;
-	dma_addr_t *pages_dma_addr;	
-	struct sg_table *sgt;
-
-	struct lima_bo_ops *ops;
-
-	struct mutex lock;
-	struct list_head va;
-
-	/* normally (resv == &_resv) except for imported bo's */
-	struct reservation_object *resv;
-	struct reservation_object _resv;
-};
-
-static inline struct lima_bo *
-to_lima_bo(struct drm_gem_object *obj)
-{
-	return container_of(obj, struct lima_bo, gem);
-}
 
 struct lima_bo *lima_gem_create_bo(struct drm_device *dev, u32 size, u32 flags);
 int lima_gem_create_handle(struct drm_device *dev, struct drm_file *file,
diff --git a/drivers/gpu/drm/lima/lima_gem_prime.c b/drivers/gpu/drm/lima/lima_gem_prime.c
index f2346d5..a690f9c 100644
--- a/drivers/gpu/drm/lima/lima_gem_prime.c
+++ b/drivers/gpu/drm/lima/lima_gem_prime.c
@@ -20,87 +20,47 @@
  * OTHER DEALINGS IN THE SOFTWARE.
  */
 
-#include <drm/drmP.h>
 #include <linux/dma-buf.h>
+#include <drm/drm_prime.h>
 
-#include "lima_gem.h"
+#include "lima_device.h"
+#include "lima_object.h"
 #include "lima_gem_prime.h"
 
-static void lima_bo_dma_buf_release(struct lima_bo *bo)
-{
-	if (bo->pages_dma_addr)
-		kfree(bo->pages_dma_addr);
-
-	if (bo->pages)
-		kfree(bo->pages);
-
-	drm_prime_gem_destroy(&bo->gem, bo->sgt);
-}
-
-static int lima_bo_dma_buf_mmap(struct lima_bo *bo, struct vm_area_struct *vma)
-{
-	return dma_buf_mmap(bo->gem.dma_buf, vma, 0);
-}
-
-static struct lima_bo_ops lima_bo_dma_buf_ops = {
-	.release = lima_bo_dma_buf_release,
-	.mmap = lima_bo_dma_buf_mmap,
-};
-
 struct drm_gem_object *lima_gem_prime_import_sg_table(
 	struct drm_device *dev, struct dma_buf_attachment *attach,
 	struct sg_table *sgt)
 {
+	struct reservation_object *resv = attach->dmabuf->resv;
+	struct lima_device *ldev = to_lima_dev(dev);
 	struct lima_bo *bo;
-	struct drm_gem_object *ret;
-	int err, npages = attach->dmabuf->size >> PAGE_SHIFT;
-
-	bo = lima_gem_create_bo(dev, attach->dmabuf->size, 0);
-	if (!bo)
-		return ERR_PTR(-ENOMEM);
 
-	bo->type = lima_bo_type_dma_buf;
-	bo->ops = &lima_bo_dma_buf_ops;
-	bo->sgt = sgt;
-
-	bo->pages_dma_addr = kzalloc(npages * sizeof(dma_addr_t), GFP_KERNEL);
-	if (!bo->pages_dma_addr) {
-		ret = ERR_PTR(-ENOMEM);
-		goto err_out;
-	}
+	ww_mutex_lock(&resv->lock, NULL);
 
-	bo->pages = kzalloc(npages * sizeof(*bo->pages), GFP_KERNEL);
-	if (!bo->pages) {
-		ret = ERR_PTR(-ENOMEM);
+	bo = lima_bo_create(ldev, attach->dmabuf->size, 0,
+			    ttm_bo_type_sg, sgt, resv);
+	if (IS_ERR(bo))
 		goto err_out;
-	}
-
-	err = drm_prime_sg_to_page_addr_arrays(
-		sgt, bo->pages, bo->pages_dma_addr, npages);
-	if (err) {
-		ret = ERR_PTR(err);
-		goto err_out;
-	}
-
-	bo->resv = attach->dmabuf->resv;
 
+	ww_mutex_unlock(&resv->lock);
 	return &bo->gem;
 
 err_out:
-	lima_gem_free_object(&bo->gem);
-	return ret;
+	ww_mutex_unlock(&resv->lock);
+	return (void *)bo;
 }
 
 struct reservation_object *lima_gem_prime_res_obj(struct drm_gem_object *obj)
 {
         struct lima_bo *bo = to_lima_bo(obj);
 
-	return bo->resv;
+	return bo->tbo.resv;
 }
 
 struct sg_table *lima_gem_prime_get_sg_table(struct drm_gem_object *obj)
 {
 	struct lima_bo *bo = to_lima_bo(obj);
+	int npages = bo->tbo.num_pages;
 
-	return drm_prime_pages_to_sg(bo->pages, obj->size >> PAGE_SHIFT);
+	return drm_prime_pages_to_sg(bo->tbo.ttm->pages, npages);
 }
diff --git a/drivers/gpu/drm/lima/lima_mmu.c b/drivers/gpu/drm/lima/lima_mmu.c
index 9e83d95..a4f6425 100644
--- a/drivers/gpu/drm/lima/lima_mmu.c
+++ b/drivers/gpu/drm/lima/lima_mmu.c
@@ -27,6 +27,7 @@
 #include "lima_device.h"
 #include "lima_mmu.h"
 #include "lima_vm.h"
+#include "lima_object.h"
 
 #define LIMA_MMU_DTE_ADDR		  0x0000
 #define LIMA_MMU_STATUS			  0x0004
@@ -132,7 +133,7 @@ int lima_mmu_init(struct lima_ip *ip)
 	}
 
 	mmu_write(INT_MASK, LIMA_MMU_INT_PAGE_FAULT | LIMA_MMU_INT_READ_BUS_ERROR);
-	mmu_write(DTE_ADDR, dev->empty_vm->pd.dma);
+	mmu_write(DTE_ADDR, *lima_bo_get_pages(dev->empty_vm->pd));
 	return lima_mmu_send_command(LIMA_MMU_COMMAND_ENABLE_PAGING,
 				     mmu_read(STATUS) & LIMA_MMU_STATUS_PAGING_ENABLED);
 }
@@ -150,7 +151,7 @@ void lima_mmu_switch_vm(struct lima_ip *ip, struct lima_vm *vm)
 			      mmu_read(STATUS) & LIMA_MMU_STATUS_STALL_ACTIVE);
 
 	if (vm)
-		mmu_write(DTE_ADDR, vm->pd.dma);
+		mmu_write(DTE_ADDR, *lima_bo_get_pages(vm->pd));
 
 	/* flush the TLB */
 	mmu_write(COMMAND, LIMA_MMU_COMMAND_ZAP_CACHE);
@@ -171,7 +172,7 @@ void lima_mmu_page_fault_resume(struct lima_ip *ip)
 		mmu_write(DTE_ADDR, 0xCAFEBABE);
 		lima_mmu_send_command(LIMA_MMU_COMMAND_HARD_RESET, mmu_read(DTE_ADDR) == 0);
 	        mmu_write(INT_MASK, LIMA_MMU_INT_PAGE_FAULT | LIMA_MMU_INT_READ_BUS_ERROR);
-		mmu_write(DTE_ADDR, dev->empty_vm->pd.dma);
+		mmu_write(DTE_ADDR, *lima_bo_get_pages(dev->empty_vm->pd));
 		lima_mmu_send_command(LIMA_MMU_COMMAND_ENABLE_PAGING,
 				      mmu_read(STATUS) & LIMA_MMU_STATUS_PAGING_ENABLED);
 	}
diff --git a/drivers/gpu/drm/lima/lima_object.c b/drivers/gpu/drm/lima/lima_object.c
new file mode 100644
index 0000000..86f5d52
--- /dev/null
+++ b/drivers/gpu/drm/lima/lima_object.c
@@ -0,0 +1,120 @@
+/*
+ * Copyright (C) 2018 Lima Project
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include <drm/drm_prime.h>
+
+#include "lima_object.h"
+
+static void lima_bo_init_placement(struct lima_bo *bo)
+{
+	struct ttm_placement *placement = &bo->placement;
+	struct ttm_place *place = &bo->place;
+
+	place->fpfn = 0;
+	place->lpfn = 0;
+	place->flags = TTM_PL_FLAG_TT | TTM_PL_FLAG_WC;
+
+	/* pin all bo for now */
+	place->flags |= TTM_PL_FLAG_NO_EVICT;
+
+	placement->num_placement = 1;
+	placement->placement = place;
+
+	placement->num_busy_placement = 1;
+	placement->busy_placement = place;
+}
+
+static void lima_bo_destroy(struct ttm_buffer_object *tbo)
+{
+	struct lima_bo *bo = ttm_to_lima_bo(tbo);
+
+	if (bo->gem.import_attach)
+		drm_prime_gem_destroy(&bo->gem, bo->tbo.sg);
+	drm_gem_object_release(&bo->gem);
+	kfree(bo);
+}
+
+struct lima_bo *lima_bo_create(struct lima_device *dev, u64 size,
+			       u32 flags, enum ttm_bo_type type,
+			       struct sg_table *sg,
+			       struct reservation_object *resv)
+{
+	struct lima_bo *bo;
+	struct ttm_mem_type_manager *man;
+	size_t acc_size;
+	int err;
+
+	size = PAGE_ALIGN(size);
+	man = dev->mman.bdev.man + TTM_PL_TT;
+	if (size >= (man->size << PAGE_SHIFT))
+		return ERR_PTR(-ENOMEM);
+
+	acc_size = ttm_bo_dma_acc_size(&dev->mman.bdev, size,
+				       sizeof(struct lima_bo));
+
+	bo = kzalloc(sizeof(*bo), GFP_KERNEL);
+	if (!bo)
+		return ERR_PTR(-ENOMEM);
+
+	drm_gem_private_object_init(dev->ddev, &bo->gem, size);
+
+	INIT_LIST_HEAD(&bo->va);
+
+	bo->tbo.bdev = &dev->mman.bdev;
+
+	lima_bo_init_placement(bo);
+
+	err = ttm_bo_init(&dev->mman.bdev, &bo->tbo, size, type,
+			  &bo->placement, 0, type != ttm_bo_type_kernel,
+			  acc_size, sg, resv, &lima_bo_destroy);
+	if (err)
+		goto err_out;
+
+	return bo;
+
+err_out:
+	kfree(bo);
+	return ERR_PTR(err);
+}
+
+dma_addr_t *lima_bo_get_pages(struct lima_bo *bo)
+{
+	struct lima_ttm_tt *ttm = (void *)bo->tbo.ttm;
+	return ttm->ttm.dma_address;
+}
+
+void *lima_bo_kmap(struct lima_bo *bo)
+{
+	bool is_iomem;
+	void *ret;
+	int err;
+
+	ret = ttm_kmap_obj_virtual(&bo->kmap, &is_iomem);
+	if (ret)
+		return ret;
+
+	err = ttm_bo_kmap(&bo->tbo, 0, bo->tbo.num_pages, &bo->kmap);
+	if (err)
+		return ERR_PTR(err);
+
+	return ttm_kmap_obj_virtual(&bo->kmap, &is_iomem);
+}
diff --git a/drivers/gpu/drm/lima/lima_object.h b/drivers/gpu/drm/lima/lima_object.h
new file mode 100644
index 0000000..8b86ec1
--- /dev/null
+++ b/drivers/gpu/drm/lima/lima_object.h
@@ -0,0 +1,87 @@
+/*
+ * Copyright (C) 2018 Lima Project
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+#ifndef __LIMA_OBJECT_H__
+#define __LIMA_OBJECT_H__
+
+#include <drm/drm_gem.h>
+#include <drm/ttm/ttm_placement.h>
+#include <drm/ttm/ttm_bo_api.h>
+
+#include "lima_device.h"
+
+struct lima_bo {
+	struct drm_gem_object gem;
+
+	struct ttm_place place;
+	struct ttm_placement placement;
+	struct ttm_buffer_object tbo;
+	struct ttm_bo_kmap_obj kmap;
+
+	struct list_head va;
+};
+
+static inline struct lima_bo *
+to_lima_bo(struct drm_gem_object *obj)
+{
+	return container_of(obj, struct lima_bo, gem);
+}
+
+static inline struct lima_bo *
+ttm_to_lima_bo(struct ttm_buffer_object *tbo)
+{
+	return container_of(tbo, struct lima_bo, tbo);
+}
+
+static inline int lima_bo_reserve(struct lima_bo *bo, bool intr)
+{
+	struct lima_device *dev = ttm_to_lima_dev(bo->tbo.bdev);
+	int r;
+
+	r = ttm_bo_reserve(&bo->tbo, intr, false, NULL);
+	if (unlikely(r != 0)) {
+		if (r != -ERESTARTSYS)
+			dev_err(dev->dev, "%p reserve failed\n", bo);
+		return r;
+	}
+	return 0;
+}
+
+static inline void lima_bo_unreserve(struct lima_bo *bo)
+{
+	ttm_bo_unreserve(&bo->tbo);
+}
+
+struct lima_bo *lima_bo_create(struct lima_device *dev, u64 size,
+			       u32 flags, enum ttm_bo_type type,
+			       struct sg_table *sg,
+			       struct reservation_object *resv);
+
+static inline void lima_bo_unref(struct lima_bo *bo)
+{
+	struct ttm_buffer_object *tbo = &bo->tbo;
+	ttm_bo_unref(&tbo);
+}
+
+dma_addr_t *lima_bo_get_pages(struct lima_bo *bo);
+void *lima_bo_kmap(struct lima_bo *bo);
+
+#endif
diff --git a/drivers/gpu/drm/lima/lima_ttm.c b/drivers/gpu/drm/lima/lima_ttm.c
new file mode 100644
index 0000000..e948e2c
--- /dev/null
+++ b/drivers/gpu/drm/lima/lima_ttm.c
@@ -0,0 +1,409 @@
+/*
+ * Copyright (C) 2018 Lima Project
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include <linux/mm.h>
+#include <drm/ttm/ttm_page_alloc.h>
+
+#include "lima_drv.h"
+#include "lima_device.h"
+#include "lima_object.h"
+
+
+static int lima_ttm_mem_global_init(struct drm_global_reference *ref)
+{
+	return ttm_mem_global_init(ref->object);
+}
+
+static void lima_ttm_mem_global_release(struct drm_global_reference *ref)
+{
+	ttm_mem_global_release(ref->object);
+}
+
+static int lima_ttm_global_init(struct lima_device *dev)
+{
+	struct drm_global_reference *global_ref;
+	int err;
+
+	dev->mman.mem_global_referenced = false;
+	global_ref = &dev->mman.mem_global_ref;
+	global_ref->global_type = DRM_GLOBAL_TTM_MEM;
+	global_ref->size = sizeof(struct ttm_mem_global);
+	global_ref->init = &lima_ttm_mem_global_init;
+	global_ref->release = &lima_ttm_mem_global_release;
+
+	err = drm_global_item_ref(global_ref);
+	if (err != 0) {
+		dev_err(dev->dev, "Failed setting up TTM memory accounting "
+			"subsystem.\n");
+		return err;
+	}
+
+	dev->mman.bo_global_ref.mem_glob =
+		dev->mman.mem_global_ref.object;
+	global_ref = &dev->mman.bo_global_ref.ref;
+	global_ref->global_type = DRM_GLOBAL_TTM_BO;
+	global_ref->size = sizeof(struct ttm_bo_global);
+	global_ref->init = &ttm_bo_global_init;
+	global_ref->release = &ttm_bo_global_release;
+	err = drm_global_item_ref(global_ref);
+	if (err != 0) {
+		dev_err(dev->dev, "Failed setting up TTM BO subsystem.\n");
+		drm_global_item_unref(&dev->mman.mem_global_ref);
+		return err;
+	}
+
+	dev->mman.mem_global_referenced = true;
+	return 0;
+}
+
+static void lima_ttm_global_fini(struct lima_device *dev)
+{
+	if (dev->mman.mem_global_referenced) {
+		drm_global_item_unref(&dev->mman.bo_global_ref.ref);
+		drm_global_item_unref(&dev->mman.mem_global_ref);
+		dev->mman.mem_global_referenced = false;
+	}
+}
+
+struct lima_tt_mgr {
+	spinlock_t lock;
+	unsigned long available;
+};
+
+static int lima_ttm_bo_man_init(struct ttm_mem_type_manager *man,
+				unsigned long p_size)
+{
+	struct lima_tt_mgr *mgr;
+
+	mgr = kmalloc(sizeof(*mgr), GFP_KERNEL);
+	if (!mgr)
+		return -ENOMEM;
+
+	spin_lock_init(&mgr->lock);
+	mgr->available = p_size;
+	man->priv = mgr;
+	return 0;
+}
+
+static int lima_ttm_bo_man_takedown(struct ttm_mem_type_manager *man)
+{
+	struct lima_tt_mgr *mgr = man->priv;
+
+	kfree(mgr);
+	man->priv = NULL;
+	return 0;
+}
+
+static int lima_ttm_bo_man_get_node(struct ttm_mem_type_manager *man,
+				    struct ttm_buffer_object *bo,
+				    const struct ttm_place *place,
+				    struct ttm_mem_reg *mem)
+{
+	struct lima_tt_mgr *mgr = man->priv;
+
+	/* don't exceed the mem limit */
+	spin_lock(&mgr->lock);
+	if (mgr->available < mem->num_pages) {
+		spin_unlock(&mgr->lock);
+		return 0;
+	}
+	mgr->available -= mem->num_pages;
+	spin_unlock(&mgr->lock);
+
+	/* just fake a non-null pointer to tell caller success */
+	mem->mm_node = (void *)1;
+	return 0;
+}
+
+static void lima_ttm_bo_man_put_node(struct ttm_mem_type_manager *man,
+				     struct ttm_mem_reg *mem)
+{
+	struct lima_tt_mgr *mgr = man->priv;
+
+	spin_lock(&mgr->lock);
+	mgr->available += mem->num_pages;
+	spin_unlock(&mgr->lock);
+
+	mem->mm_node = NULL;
+}
+
+static void lima_ttm_bo_man_debug(struct ttm_mem_type_manager *man,
+				  struct drm_printer *printer)
+{
+}
+
+static const struct ttm_mem_type_manager_func lima_bo_manager_func = {
+	.init = lima_ttm_bo_man_init,
+	.takedown = lima_ttm_bo_man_takedown,
+	.get_node = lima_ttm_bo_man_get_node,
+	.put_node = lima_ttm_bo_man_put_node,
+	.debug = lima_ttm_bo_man_debug
+};
+
+static int lima_init_mem_type(struct ttm_bo_device *bdev, uint32_t type,
+			      struct ttm_mem_type_manager *man)
+{
+	struct lima_device *dev = ttm_to_lima_dev(bdev);
+
+	switch (type) {
+	case TTM_PL_SYSTEM:
+		/* System memory */
+		man->flags = TTM_MEMTYPE_FLAG_MAPPABLE;
+		man->available_caching = TTM_PL_MASK_CACHING;
+		man->default_caching = TTM_PL_FLAG_CACHED;
+		break;
+	case TTM_PL_TT:
+		man->func = &lima_bo_manager_func;
+		man->flags = TTM_MEMTYPE_FLAG_MAPPABLE;
+		man->available_caching = TTM_PL_MASK_CACHING;
+		man->default_caching = TTM_PL_FLAG_CACHED;
+		break;
+	default:
+		dev_err(dev->dev, "Unsupported memory type %u\n",
+			(unsigned int)type);
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static int lima_ttm_backend_bind(struct ttm_tt *ttm,
+				 struct ttm_mem_reg *bo_mem)
+{
+	return 0;
+}
+
+static int lima_ttm_backend_unbind(struct ttm_tt *ttm)
+{
+	return 0;
+}
+
+static void lima_ttm_backend_destroy(struct ttm_tt *ttm)
+{
+	struct lima_ttm_tt *tt = (void *)ttm;
+
+	ttm_dma_tt_fini(&tt->ttm);
+	kfree(tt);
+}
+
+static struct ttm_backend_func lima_ttm_backend_func = {
+	.bind = &lima_ttm_backend_bind,
+	.unbind = &lima_ttm_backend_unbind,
+	.destroy = &lima_ttm_backend_destroy,
+};
+
+static struct ttm_tt *lima_ttm_tt_create(struct ttm_buffer_object *bo,
+					 uint32_t page_flags)
+{
+	struct lima_ttm_tt *tt;
+
+	tt = kzalloc(sizeof(struct lima_ttm_tt), GFP_KERNEL);
+	if (tt == NULL)
+		return NULL;
+
+	tt->ttm.ttm.func = &lima_ttm_backend_func;
+
+	if (ttm_sg_tt_init(&tt->ttm, bo, page_flags)) {
+		kfree(tt);
+		return NULL;
+	}
+
+	return &tt->ttm.ttm;
+}
+
+static int lima_ttm_tt_populate(struct ttm_tt *ttm,
+				struct ttm_operation_ctx *ctx)
+{
+	struct lima_device *dev = ttm_to_lima_dev(ttm->bdev);
+	struct lima_ttm_tt *tt = (void *)ttm;
+	bool slave = !!(ttm->page_flags & TTM_PAGE_FLAG_SG);
+
+	if (slave) {
+		drm_prime_sg_to_page_addr_arrays(ttm->sg, ttm->pages,
+						 tt->ttm.dma_address,
+						 ttm->num_pages);
+		ttm->state = tt_unbound;
+		return 0;
+	}
+
+	return ttm_populate_and_map_pages(dev->dev, &tt->ttm, ctx);
+}
+
+static void lima_ttm_tt_unpopulate(struct ttm_tt *ttm)
+{
+	struct lima_device *dev = ttm_to_lima_dev(ttm->bdev);
+	struct lima_ttm_tt *tt = (void *)ttm;
+	bool slave = !!(ttm->page_flags & TTM_PAGE_FLAG_SG);
+
+	if (slave)
+		return;
+
+	ttm_unmap_and_unpopulate_pages(dev->dev, &tt->ttm);
+}
+
+static int lima_invalidate_caches(struct ttm_bo_device *bdev,
+				  uint32_t flags)
+{
+	struct lima_device *dev = ttm_to_lima_dev(bdev);
+
+	dev_err(dev->dev, "%s not implemented\n", __FUNCTION__);
+	return 0;
+}
+
+static void lima_evict_flags(struct ttm_buffer_object *tbo,
+			     struct ttm_placement *placement)
+{
+	struct lima_bo *bo = ttm_to_lima_bo(tbo);
+	struct lima_device *dev = to_lima_dev(bo->gem.dev);
+
+	dev_err(dev->dev, "%s not implemented\n", __FUNCTION__);
+}
+
+static int lima_verify_access(struct ttm_buffer_object *tbo,
+			      struct file *filp)
+{
+	struct lima_bo *bo = ttm_to_lima_bo(tbo);
+
+	return drm_vma_node_verify_access(&bo->gem.vma_node,
+					  filp->private_data);
+}
+
+static int lima_ttm_io_mem_reserve(struct ttm_bo_device *bdev,
+				   struct ttm_mem_reg *mem)
+{
+	struct ttm_mem_type_manager *man = &bdev->man[mem->mem_type];
+
+	mem->bus.addr = NULL;
+	mem->bus.offset = 0;
+	mem->bus.size = mem->num_pages << PAGE_SHIFT;
+	mem->bus.base = 0;
+	mem->bus.is_iomem = false;
+
+	if (!(man->flags & TTM_MEMTYPE_FLAG_MAPPABLE))
+		return -EINVAL;
+
+	switch (mem->mem_type) {
+	case TTM_PL_SYSTEM:
+	case TTM_PL_TT:
+		return 0;
+	default:
+		return -EINVAL;
+	}
+	return 0;
+}
+
+static void lima_ttm_io_mem_free(struct ttm_bo_device *bdev,
+				 struct ttm_mem_reg *mem)
+{
+
+}
+
+static void lima_bo_move_notify(struct ttm_buffer_object *tbo, bool evict,
+				struct ttm_mem_reg *new_mem)
+{
+	struct lima_bo *bo = ttm_to_lima_bo(tbo);
+	struct lima_device *dev = to_lima_dev(bo->gem.dev);
+
+	if (evict)
+		dev_err(dev->dev, "%s not implemented\n", __FUNCTION__);
+}
+
+static void lima_bo_swap_notify(struct ttm_buffer_object *tbo)
+{
+	struct lima_bo *bo = ttm_to_lima_bo(tbo);
+	struct lima_device *dev = to_lima_dev(bo->gem.dev);
+
+	dev_err(dev->dev, "%s not implemented\n", __FUNCTION__);
+}
+
+static struct ttm_bo_driver lima_bo_driver = {
+	.ttm_tt_create = lima_ttm_tt_create,
+	.ttm_tt_populate = lima_ttm_tt_populate,
+	.ttm_tt_unpopulate = lima_ttm_tt_unpopulate,
+	.invalidate_caches = lima_invalidate_caches,
+	.init_mem_type = lima_init_mem_type,
+	.eviction_valuable = ttm_bo_eviction_valuable,
+	.evict_flags = lima_evict_flags,
+	.verify_access = lima_verify_access,
+	.io_mem_reserve = lima_ttm_io_mem_reserve,
+	.io_mem_free = lima_ttm_io_mem_free,
+	.move_notify = lima_bo_move_notify,
+	.swap_notify = lima_bo_swap_notify,
+};
+
+int lima_ttm_init(struct lima_device *dev)
+{
+	int err;
+	bool need_dma32;
+	u64 gtt_size;
+
+	err = lima_ttm_global_init(dev);
+	if (err)
+		return err;
+
+#if defined(CONFIG_ARM) && !defined(CONFIG_ARM_LPAE)
+	need_dma32 = false;
+#else
+	need_dma32 = true;
+#endif
+
+	err = ttm_bo_device_init(&dev->mman.bdev,
+				 dev->mman.bo_global_ref.ref.object,
+				 &lima_bo_driver,
+				 dev->ddev->anon_inode->i_mapping,
+				 DRM_FILE_PAGE_OFFSET,
+				 need_dma32);
+	if (err) {
+		dev_err(dev->dev, "failed initializing buffer object "
+			"driver(%d).\n", err);
+		goto err_out0;
+	}
+
+	if (lima_max_mem < 0) {
+		struct sysinfo si;
+		si_meminfo(&si);
+		/* TODO: better to have lower 32 mem size */
+		gtt_size = min(((u64)si.totalram * si.mem_unit * 3/4),
+			       0x100000000ULL);
+	}
+	else
+		gtt_size = (u64)lima_max_mem << 20;
+
+	err = ttm_bo_init_mm(&dev->mman.bdev, TTM_PL_TT, gtt_size >> PAGE_SHIFT);
+	if (err) {
+		dev_err(dev->dev, "Failed initializing GTT heap.\n");
+		goto err_out1;
+	}
+	return 0;
+
+err_out1:
+	ttm_bo_device_release(&dev->mman.bdev);
+err_out0:
+	lima_ttm_global_fini(dev);
+	return err;
+}
+
+void lima_ttm_fini(struct lima_device *dev)
+{
+	ttm_bo_device_release(&dev->mman.bdev);
+	lima_ttm_global_fini(dev);
+	dev_info(dev->dev, "ttm finalized\n");
+}
diff --git a/drivers/gpu/drm/lima/lima_ttm.h b/drivers/gpu/drm/lima/lima_ttm.h
new file mode 100644
index 0000000..c166945
--- /dev/null
+++ b/drivers/gpu/drm/lima/lima_ttm.h
@@ -0,0 +1,44 @@
+/*
+ * Copyright (C) 2018 Lima Project
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the "Software"),
+ * to deal in the Software without restriction, including without limitation
+ * the rights to use, copy, modify, merge, publish, distribute, sublicense,
+ * and/or sell copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.  IN NO EVENT SHALL
+ * THE COPYRIGHT HOLDER(S) OR AUTHOR(S) BE LIABLE FOR ANY CLAIM, DAMAGES OR
+ * OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
+ * ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ */
+#ifndef __LIMA_TTM_H__
+#define __LIMA_TTM_H__
+
+#include <drm/ttm/ttm_bo_driver.h>
+
+struct lima_mman {
+	struct ttm_bo_global_ref bo_global_ref;
+	struct drm_global_reference mem_global_ref;
+	struct ttm_bo_device bdev;
+	bool mem_global_referenced;
+};
+
+struct lima_ttm_tt {
+	struct ttm_dma_tt ttm;
+};
+
+struct lima_device;
+struct lima_bo;
+
+int lima_ttm_init(struct lima_device *dev);
+void lima_ttm_fini(struct lima_device *dev);
+
+#endif
diff --git a/drivers/gpu/drm/lima/lima_vm.c b/drivers/gpu/drm/lima/lima_vm.c
index 0eb2e72..7448840 100644
--- a/drivers/gpu/drm/lima/lima_vm.c
+++ b/drivers/gpu/drm/lima/lima_vm.c
@@ -4,6 +4,24 @@
 
 #include "lima_device.h"
 #include "lima_vm.h"
+#include "lima_object.h"
+
+struct lima_bo_va_mapping {
+	struct list_head list;
+	struct rb_node rb;
+	uint32_t start;
+	uint32_t last;
+	uint32_t __subtree_last;
+};
+
+struct lima_bo_va {
+	struct list_head list;
+	unsigned ref_count;
+
+	struct list_head mapping;
+
+	struct lima_vm *vm;
+};
 
 #define LIMA_PDE(va) (va >> 22)
 #define LIMA_PTE(va) ((va & 0x3FFFFF) >> 12)
@@ -50,17 +68,10 @@ static void lima_vm_unmap_page_table(struct lima_vm *vm, u32 start, u32 end)
 	for (addr = start; addr <= end; addr += LIMA_PAGE_SIZE) {
 		u32 pde = LIMA_PDE(addr);
 		u32 pte = LIMA_PTE(addr);
+		u32 *pt;
 
-		vm->pts[pde].cpu[pte] = 0;
-		vm->pts[pde].dma--;
-		if (!(vm->pts[pde].dma & LIMA_PAGE_MASK)) {
-			vm->pd.cpu[pde] = 0;
-			vm->pd.dma--;
-
-			dma_free_wc(vm->dev->dev, LIMA_PAGE_SIZE,
-				    vm->pts[pde].cpu, vm->pts[pde].dma);
-			vm->pts[pde].cpu = 0;
-		}
+		pt = lima_bo_kmap(vm->pt[pde]);
+		pt[pte] = 0;
 	}
 }
 
@@ -68,101 +79,197 @@ static int lima_vm_map_page_table(struct lima_vm *vm, dma_addr_t *dma,
 				  u32 start, u32 end)
 {
 	u64 addr;
-	int i = 0;
+	int err, i = 0;
 
 	for (addr = start; addr <= end; addr += LIMA_PAGE_SIZE) {
 		u32 pde = LIMA_PDE(addr);
 		u32 pte = LIMA_PTE(addr);
+		u32 *pd, *pt;
+
+		if (vm->pt[pde])
+			pt = lima_bo_kmap(vm->pt[pde]);
+		else {
+			vm->pt[pde] = lima_bo_create(
+				vm->dev, LIMA_PAGE_SIZE, 0, ttm_bo_type_kernel,
+				NULL, vm->pd->tbo.resv);
+			if (IS_ERR(vm->pt[pde])) {
+				err = PTR_ERR(vm->pt[pde]);
+				goto err_out;
+			}
 
-		if (!vm->pts[pde].cpu) {
-			vm->pts[pde].cpu =
-				dma_alloc_wc(vm->dev->dev, LIMA_PAGE_SIZE,
-					     &vm->pts[pde].dma, GFP_KERNEL);
-			if (!vm->pts[pde].cpu) {
-				if (addr != start)
-					lima_vm_unmap_page_table(vm, start, addr - 1);
-				return -ENOMEM;
+			pt = lima_bo_kmap(vm->pt[pde]);
+			if (IS_ERR(pt)) {
+				err = PTR_ERR(pt);
+				goto err_out;
 			}
-			memset(vm->pts[pde].cpu, 0, LIMA_PAGE_SIZE);
-			vm->pd.cpu[pde] = vm->pts[pde].dma | LIMA_VM_FLAG_PRESENT;
-			vm->pd.dma++;
+
+			pd = lima_bo_kmap(vm->pd);
+			pd[pde] = *lima_bo_get_pages(vm->pt[pde]) | LIMA_VM_FLAG_PRESENT;
 		}
 
-		/* dma address should be 4K aligned, so use the lower 12 bit
-		 * as a reference count, 12bit is enough for 1024 max count
-		 */
-		vm->pts[pde].dma++;
-		vm->pts[pde].cpu[pte] = dma[i++] | LIMA_VM_FLAGS_CACHE;
+		pt[pte] = dma[i++] | LIMA_VM_FLAGS_CACHE;
 	}
 
 	return 0;
+
+err_out:
+	if (addr != start)
+		lima_vm_unmap_page_table(vm, start, addr - 1);
+	return err;
 }
 
-int lima_vm_map(struct lima_vm *vm, dma_addr_t *pages_dma,
-		struct lima_bo_va_mapping *mapping)
+static struct lima_bo_va *
+lima_vm_bo_find(struct lima_vm *vm, struct lima_bo *bo)
 {
-	int err;
-	struct lima_bo_va_mapping *it;
+	struct lima_bo_va *bo_va, *ret = NULL;
 
-	mutex_lock(&vm->lock);
+	list_for_each_entry(bo_va, &bo->va, list) {
+		if (bo_va->vm == vm) {
+			ret = bo_va;
+			break;
+		}
+	}
 
-	it = lima_vm_it_iter_first(&vm->va, mapping->start, mapping->last);
+	return ret;
+}
+
+int lima_vm_bo_map(struct lima_vm *vm, struct lima_bo *bo, u32 start)
+{
+	int err;
+	struct lima_bo_va_mapping *it, *mapping;
+	u32 end = start + bo->gem.size - 1;
+	dma_addr_t *pages_dma = lima_bo_get_pages(bo);
+	struct lima_bo_va *bo_va;
+
+	it = lima_vm_it_iter_first(&vm->va, start, end);
 	if (it) {
-		dev_err(vm->dev->dev, "lima vm map va overlap %x-%x %x-%x\n",
-			mapping->start, mapping->last, it->start, it->last);
-		err = -EINVAL;
-		goto err_out0;
+		dev_dbg(bo->gem.dev->dev, "lima vm map va overlap %x-%x %x-%x\n",
+			start, end, it->start, it->last);
+		return -EINVAL;
 	}
 
-	err = lima_vm_map_page_table(
-		vm, pages_dma, mapping->start, mapping->last);
-	if (err)
-		goto err_out0;
+	mapping = kmalloc(sizeof(*mapping), GFP_KERNEL);
+	if (!mapping)
+		return -ENOMEM;
+	mapping->start = start;
+	mapping->last = end;
+
+	err = lima_vm_map_page_table(vm, pages_dma, start, end);
+	if (err) {
+		kfree(mapping);
+		return err;
+	}
 
 	lima_vm_it_insert(mapping, &vm->va);
 
-	mutex_unlock(&vm->lock);
-	return 0;
+	bo_va = lima_vm_bo_find(vm, bo);
+	list_add_tail(&mapping->list, &bo_va->mapping);
 
-err_out0:
-	mutex_unlock(&vm->lock);
-	return err;
+	return 0;
 }
 
-int lima_vm_unmap(struct lima_vm *vm, struct lima_bo_va_mapping *mapping)
+static void lima_vm_unmap(struct lima_vm *vm,
+			  struct lima_bo_va_mapping *mapping)
 {
-	mutex_lock(&vm->lock);
-
 	lima_vm_it_remove(mapping, &vm->va);
 
 	lima_vm_unmap_page_table(vm, mapping->start, mapping->last);
 
-	mutex_unlock(&vm->lock);
+	list_del(&mapping->list);
+	kfree(mapping);
+}
+
+int lima_vm_bo_unmap(struct lima_vm *vm, struct lima_bo *bo, u32 start)
+{
+	struct lima_bo_va *bo_va;
+	struct lima_bo_va_mapping *mapping;
+	int err;
 
-	/* TODO: zap MMU using this vm in case buggy user app
-	 * free bo during GP/PP running which may corrupt kernel
-	 * reusing this memory. */
+	bo_va = lima_vm_bo_find(vm, bo);
+	list_for_each_entry(mapping, &bo_va->mapping, list) {
+		if (mapping->start == start) {
+			/* wait bo idle before unmap it from vm */
+			err = ttm_bo_wait(&bo->tbo, false, false);
+			if (err) {
+				dev_err(vm->dev->dev, "bo unmap fail to "
+					"wait bo (%d)\n", err);
+				return err;
+			}
+		        lima_vm_unmap(vm, mapping);
+			break;
+		}
+	}
 
 	return 0;
 }
 
+int lima_vm_bo_add(struct lima_vm *vm, struct lima_bo *bo)
+{
+	struct lima_bo_va *bo_va;
+
+	bo_va = lima_vm_bo_find(vm, bo);
+	if (bo_va) {
+		bo_va->ref_count++;
+		return 0;
+	}
+
+	bo_va = kmalloc(sizeof(*bo_va), GFP_KERNEL);
+	if (!bo_va)
+		return -ENOMEM;
+
+	bo_va->vm = vm;
+	bo_va->ref_count = 1;
+	INIT_LIST_HEAD(&bo_va->mapping);
+	list_add_tail(&bo_va->list, &bo->va);
+	return 0;
+}
+
+int lima_vm_bo_del(struct lima_vm *vm, struct lima_bo *bo)
+{
+	struct lima_bo_va *bo_va;
+	struct lima_bo_va_mapping *mapping, *tmp;
+	int err;
+
+	bo_va = lima_vm_bo_find(vm, bo);
+	if (--bo_va->ref_count > 0)
+		return 0;
+
+	/* wait bo idle before unmap it from vm */
+	err = ttm_bo_wait(&bo->tbo, false, false);
+	if (err) {
+		dev_err(vm->dev->dev, "bo del fail to wait bo (%d)\n", err);
+		return err;
+	}
+
+	list_for_each_entry_safe(mapping, tmp, &bo_va->mapping, list) {
+	        lima_vm_unmap(vm, mapping);
+	}
+	list_del(&bo_va->list);
+	kfree(bo_va);
+	return 0;
+}
+
 struct lima_vm *lima_vm_create(struct lima_device *dev)
 {
 	struct lima_vm *vm;
+	void *pd;
 
-	vm = kvzalloc(sizeof(*vm), GFP_KERNEL);
+	vm = kzalloc(sizeof(*vm), GFP_KERNEL);
 	if (!vm)
 		return NULL;
 
 	vm->dev = dev;
 	vm->va = RB_ROOT_CACHED;
-	mutex_init(&vm->lock);
 	kref_init(&vm->refcount);
 
-	vm->pd.cpu = dma_alloc_wc(dev->dev, LIMA_PAGE_SIZE, &vm->pd.dma, GFP_KERNEL);
-	if (!vm->pd.cpu)
+	vm->pd = lima_bo_create(dev, LIMA_PAGE_SIZE, 0,
+				ttm_bo_type_kernel, NULL, NULL);
+	if (IS_ERR(vm->pd))
 		goto err_out0;
-	memset(vm->pd.cpu, 0, LIMA_PAGE_SIZE);
+
+	pd = lima_bo_kmap(vm->pd);
+	if (IS_ERR(pd))
+		goto err_out1;
 
 	if (dev->dlbu_cpu) {
 		int err = lima_vm_map_page_table(
@@ -175,9 +282,9 @@ struct lima_vm *lima_vm_create(struct lima_device *dev)
 	return vm;
 
 err_out1:
-	dma_free_wc(dev->dev, LIMA_PAGE_SIZE, vm->pd.cpu, vm->pd.dma);
+	lima_bo_unref(vm->pd);
 err_out0:
-	kvfree(vm);
+	kfree(vm);
 	return NULL;
 }
 
@@ -191,41 +298,33 @@ void lima_vm_release(struct kref *kref)
 		dev_err(dev->dev, "still active bo inside vm\n");
 	}
 
-	for (i = 0; (vm->pd.dma & LIMA_PAGE_MASK) && i < LIMA_PAGE_ENT_NUM; i++) {
-		if (vm->pts[i].cpu) {
-			dma_free_wc(vm->dev->dev, LIMA_PAGE_SIZE,
-				    vm->pts[i].cpu, vm->pts[i].dma & ~LIMA_PAGE_MASK);
-			vm->pd.dma--;
-		}
+	for (i = 0; i < LIMA_PAGE_ENT_NUM; i++) {
+		if (vm->pt[i])
+			lima_bo_unref(vm->pt[i]);
 	}
 
-	if (vm->pd.cpu)
-		dma_free_wc(vm->dev->dev, LIMA_PAGE_SIZE, vm->pd.cpu,
-			    vm->pd.dma & ~LIMA_PAGE_MASK);
+	if (vm->pd)
+	        lima_bo_unref(vm->pd);
 
-	kvfree(vm);
+	kfree(vm);
 }
 
 void lima_vm_print(struct lima_vm *vm)
 {
 	int i, j;
+	u32 *pd = lima_bo_kmap(vm->pd);
 
 	/* to avoid the defined by not used warning */
 	(void)&lima_vm_it_iter_next;
 
-	if (!vm->pd.cpu)
-		return;
-
 	for (i = 0; i < LIMA_PAGE_ENT_NUM; i++) {
-		if (vm->pd.cpu[i]) {
-			printk(KERN_INFO "lima vm pd %03x:%08x\n", i, vm->pd.cpu[i]);
-			if ((vm->pd.cpu[i] & ~LIMA_VM_FLAG_MASK) != vm->pts[i].dma)
-				printk(KERN_INFO "pd %x not match pt %x\n",
-				       i, (u32)vm->pts[i].dma);
+		if (pd[i]) {
+			u32 *pt = lima_bo_kmap(vm->pt[i]);
+
+			printk(KERN_INFO "lima vm pd %03x:%08x\n", i, pd[i]);
 			for (j = 0; j < LIMA_PAGE_ENT_NUM; j++) {
-				if (vm->pts[i].cpu[j])
-					printk(KERN_INFO "  pt %03x:%08x\n",
-					       j, vm->pts[i].cpu[j]);
+				if (pt[j])
+					printk(KERN_INFO "  pt %03x:%08x\n", j, pt[j]);
 			}
 		}
 	}
diff --git a/drivers/gpu/drm/lima/lima_vm.h b/drivers/gpu/drm/lima/lima_vm.h
index 518e12a..38ecc92 100644
--- a/drivers/gpu/drm/lima/lima_vm.h
+++ b/drivers/gpu/drm/lima/lima_vm.h
@@ -22,7 +22,6 @@
 #ifndef __LIMA_VM_H__
 #define __LIMA_VM_H__
 
-#include <linux/mutex.h>
 #include <linux/rbtree.h>
 #include <linux/kref.h>
 
@@ -34,34 +33,27 @@
 #define LIMA_VA_RESERVE_DLBU   LIMA_VA_RESERVE_START
 #define LIMA_VA_RESERVE_END    0x100000000
 
+struct lima_bo;
 struct lima_device;
 
-struct lima_vm_page {
-	u32 *cpu;
-	dma_addr_t dma;
-};
-
-struct lima_bo_va_mapping {
-	struct list_head list;
-	struct rb_node rb;
-	uint32_t start;
-	uint32_t last;
-	uint32_t __subtree_last;
-};
-
 struct lima_vm {
-	struct mutex lock;
 	struct kref refcount;
 
-	struct lima_device *dev;
-
 	/* tree of virtual addresses mapped */
 	struct rb_root_cached va;
 
-        struct lima_vm_page pd;
-	struct lima_vm_page pts[LIMA_PAGE_ENT_NUM];
+	struct lima_device *dev;
+
+	struct lima_bo *pd;
+	struct lima_bo *pt[LIMA_PAGE_ENT_NUM];
 };
 
+int lima_vm_bo_map(struct lima_vm *vm, struct lima_bo *bo, u32 start);
+int lima_vm_bo_unmap(struct lima_vm *vm, struct lima_bo *bo, u32 start);
+
+int lima_vm_bo_add(struct lima_vm *vm, struct lima_bo *bo);
+int lima_vm_bo_del(struct lima_vm *vm, struct lima_bo *bo);
+
 struct lima_vm *lima_vm_create(struct lima_device *dev);
 void lima_vm_release(struct kref *kref);
 
@@ -76,10 +68,6 @@ static inline void lima_vm_put(struct lima_vm *vm)
 	kref_put(&vm->refcount, lima_vm_release);
 }
 
-int lima_vm_map(struct lima_vm *vm, dma_addr_t *pages_dma,
-		struct lima_bo_va_mapping *mapping);
-int lima_vm_unmap(struct lima_vm *vm, struct lima_bo_va_mapping *mapping);
-
 void lima_vm_print(struct lima_vm *vm);
 
 #endif
-- 
2.0.1

